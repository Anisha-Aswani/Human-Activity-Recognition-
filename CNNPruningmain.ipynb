{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNmain.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1miUoB4oiUak"
      },
      "source": [
        "#Importing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm_qOCm9-7Ty"
      },
      "source": [
        "# Tensorflow version 2.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPdC7ARm-96-"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rBmvausn-RDV",
        "outputId": "4f5ee37c-6cf7-4a33-ecb6-b1722fc8d550"
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_Hq0VUMvJx9"
      },
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from scipy import ndimage\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D,Conv2D\n",
        "from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n",
        "from keras.layers import BatchNormalization,ReLU,GlobalAveragePooling1D,MaxPooling1D,LSTM,TimeDistributed,GlobalAveragePooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import save_model, load_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import  plot_model\n",
        "from keras.models import Model,save_model,load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import expand_dims\n",
        "from tensorflow import keras\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8tRrh2Q2gnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee804e03-573f-4911-926a-40b1022473d6"
      },
      "source": [
        "!pip install -U tensorboard_plugin_profile"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboard_plugin_profile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/4e/0bf160776e5dacdba5105a580aa57a2bd37c1cc4faa1bd7695d82e7d6ae7/tensorboard_plugin_profile-2.4.0-py3-none-any.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 29.9MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 24.8MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 28.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 25.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 28.2MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 18.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 81kB 19.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 18.4MB/s eta 0:00:01\r\u001b[K     |██▉                             | 102kB 18.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112kB 18.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 122kB 18.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 133kB 18.3MB/s eta 0:00:01\r\u001b[K     |████                            | 143kB 18.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 153kB 18.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 163kB 18.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 174kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 194kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 204kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 215kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 225kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 235kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 245kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 256kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 266kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 276kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 286kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 296kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 307kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 317kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 327kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 337kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 348kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 358kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 368kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 378kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 389kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 399kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 409kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 419kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 430kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 440kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 450kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 460kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 471kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 481kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 491kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 501kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 512kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 522kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 532kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 542kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 552kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 563kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 573kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 583kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 593kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 604kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 614kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 624kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 634kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 645kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 655kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 665kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 675kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 686kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 696kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 706kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 716kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 727kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 737kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 747kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 757kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 768kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 778kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 788kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 798kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 808kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 819kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 829kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 839kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 849kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 860kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 870kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 880kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 890kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 901kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 911kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 921kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 931kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 942kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 952kB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 962kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 972kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 983kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 993kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.0MB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.0MB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.0MB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0MB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.1MB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.1MB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1MB 18.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1MB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1MB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 18.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (56.0.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (3.12.4)\n",
            "Collecting gviz-api>=1.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/8f/c6f16235a16b3dc4efdcf34dbc93b3b6f678b88176dbd6a36c75d678888f/gviz_api-1.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (1.15.0)\n",
            "Installing collected packages: gviz-api, tensorboard-plugin-profile\n",
            "Successfully installed gviz-api-1.9.0 tensorboard-plugin-profile-2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INpMNpCdimZr"
      },
      "source": [
        "#Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2irnh55lB6",
        "outputId": "3e096673-d150-4486-b93e-a22ce8f0c80d"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/UCI HAR Dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-28 19:37:46--  https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60999314 (58M) [application/x-httpd-php]\n",
            "Saving to: ‘UCI HAR Dataset.zip’\n",
            "\n",
            "UCI HAR Dataset.zip 100%[===================>]  58.17M  32.2MB/s    in 1.8s    \n",
            "\n",
            "2021-04-28 19:37:48 (32.2 MB/s) - ‘UCI HAR Dataset.zip’ saved [60999314/60999314]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vYcHaInEDoK"
      },
      "source": [
        "def load_file(filepath):\n",
        "  dataframe=read_csv(filepath,header=None,delim_whitespace=True)\n",
        "  return dataframe.values"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7akEplVIDyX"
      },
      "source": [
        "def load_group(filenames,prefix=''):\n",
        "  loaded=list()\n",
        "  for name in filenames:\n",
        "    data=load_file(prefix+name)\n",
        "    loaded.append(data)\n",
        "  loaded=dstack(loaded)\n",
        "  return loaded"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKHYErTsIYac"
      },
      "source": [
        "def load_dataset_group(group,prefix=''):\n",
        "  filepath=prefix+group+'/Inertial Signals/'\n",
        "  filenames=list()\n",
        "  filenames+=['total_acc_x_'+group+'.txt','total_acc_y_'+group+'.txt','total_acc_z_'+group+'.txt']\n",
        "  filenames+=['body_acc_x_'+group+'.txt','body_acc_y_'+group+'.txt','body_acc_z_'+group+'.txt']\n",
        "  filenames+=['body_gyro_x_'+group+'.txt','body_gyro_y_'+group+'.txt','body_gyro_z_'+group+'.txt']\n",
        "  X=load_group(filenames,filepath)\n",
        "  y=load_file(prefix+group+'/y_'+group+'.txt')\n",
        "  return (X,y)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuWfdQHuJt9f"
      },
      "source": [
        "def load_dataset(prefix=''):\n",
        "  trainX,trainy=load_dataset_group('train',prefix+'UCI HAR Dataset/')\n",
        "  print(trainX.shape,trainy.shape)\n",
        "  testX,testy=load_dataset_group('test',prefix+'UCI HAR Dataset/')\n",
        "  print(testX.shape,testy.shape)\n",
        "  trainy=trainy-1\n",
        "  testy=testy-1\n",
        "  trainy=to_categorical(trainy)\n",
        "  testy=to_categorical(testy)\n",
        "  print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "  return trainX, trainy, testX, testy"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Mtbf_PSH87"
      },
      "source": [
        "def scale_data(trainX, testX):\n",
        "\t# remove overlap\n",
        "\tcut = int(trainX.shape[1] / 2)\n",
        "\tlongX = trainX[:, -cut:, :]\n",
        "\t# flatten windows\n",
        "\tlongX = longX.reshape((longX.shape[0] * longX.shape[1], longX.shape[2]))\n",
        "\t# flatten train and test\n",
        "\tflatTrainX = trainX.reshape((trainX.shape[0] * trainX.shape[1], trainX.shape[2]))\n",
        "\tflatTestX = testX.reshape((testX.shape[0] * testX.shape[1], testX.shape[2]))\n",
        "\t# standardize\n",
        "\n",
        "\ts = StandardScaler()\n",
        "\t\t# fit on training data\n",
        "\ts.fit(longX)\n",
        "\t\t# apply to training and test data\n",
        "\tlongX = s.transform(longX)\n",
        "\tflatTrainX = s.transform(flatTrainX)\n",
        "\tflatTestX = s.transform(flatTestX)\n",
        "\t# reshape\n",
        "\tflatTrainX = flatTrainX.reshape((trainX.shape))\n",
        "\tflatTestX = flatTestX.reshape((testX.shape))\n",
        "\treturn flatTrainX, flatTestX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dow8qJO4myQ"
      },
      "source": [
        "##Function for model size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytB8g1p74mEU"
      },
      "source": [
        "def get_zipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  zipped_file = file+'.zip'\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOWuN0ZroUDR"
      },
      "source": [
        "##1. CNN MODEL\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7BkQ1pYraEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45adfda4-32c7-44fe-cdaf-f49a002caaef"
      },
      "source": [
        "trainX,trainy,testX,testy=load_dataset()\n",
        "verbose,epochs,batch_size=1,500,32 #Epoch 500\n",
        "n_timesteps,n_features,n_outputs=trainX.shape[1],trainX.shape[2],trainy.shape[1]\n",
        "print('n step: ', n_timesteps)\n",
        "print('features: ',n_features)\n",
        "trainX,testX=scale_data(trainX,testX)\n",
        "print(trainX.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
            "n step:  128\n",
            "features:  9\n",
            "(7352, 128, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yciMN9WVMkpd"
      },
      "source": [
        "'''\n",
        "inputs=keras.Input(shape=(n_timesteps,n_features))\n",
        "\n",
        "\n",
        "conv_1=tf.keras.layers.Conv1D(filters=64,kernel_size=5,strides=2,activation='relu')(inputs)\n",
        "maxpool_1=tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)(conv_1)\n",
        "\n",
        "conv_2=tf.keras.layers.Conv1D(filters=128,kernel_size=3,strides=1,activation='relu')(maxpool_1)\n",
        "maxpool_2=tf.keras.layers.MaxPooling1D(pool_size=2,strides=1)(conv_2)\n",
        "\n",
        "conv_3=tf.keras.layers.Conv1D(filters=32,kernel_size=3,strides=1,activation='relu')(maxpool_2)\n",
        "avg_pooling=tf.keras.layers.GlobalAveragePooling1D()(conv_3)\n",
        "batch_norm=tf.keras.layers.BatchNormalization()(avg_pooling)\n",
        "\n",
        "output=tf.keras.layers.Dense(n_outputs,activation='softmax')(batch_norm)\n",
        "model=tf.keras.Model(inputs=inputs,outputs=output)\n",
        "'''\n",
        "inputs=keras.Input(shape=(n_timesteps,n_features))\n",
        "\n",
        "\n",
        "conv_1=tf.keras.layers.Conv1D(filters=64,kernel_size=5,strides=2,activation='relu')(inputs)\n",
        "maxpool_1=tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)(conv_1)\n",
        "\n",
        "conv_2=tf.keras.layers.Conv1D(filters=128,kernel_size=3,strides=1,activation='relu')(maxpool_1)\n",
        "maxpool_2=tf.keras.layers.MaxPooling1D(pool_size=2,strides=1)(conv_2)\n",
        "\n",
        "conv_3=tf.keras.layers.Conv1D(filters=32,kernel_size=3,strides=1,activation='relu')(maxpool_2)\n",
        "avg_pooling=tf.keras.layers.GlobalAveragePooling1D()(conv_3)\n",
        "batch_norm=tf.keras.layers.BatchNormalization()(avg_pooling)\n",
        "\n",
        "output=tf.keras.layers.Dense(n_outputs,activation='softmax')(batch_norm)\n",
        "model=tf.keras.Model(inputs=inputs,outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEENq8DHseVI"
      },
      "source": [
        "plot_model(model, show_shapes=True, to_file='CNN_Model.png')\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2vsYhbK2tvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b84903-002b-400a-ee96-808778f46185"
      },
      "source": [
        "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
        "                                                 histogram_freq = 1,\n",
        "                                                 )\n",
        "\n",
        "model.fit(trainX,trainy,epochs=epochs,batch_size=batch_size,verbose=verbose,callbacks=[tboard_callback])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "230/230 [==============================] - 5s 9ms/step - loss: 0.4289 - accuracy: 0.8808\n",
            "Epoch 2/5\n",
            "230/230 [==============================] - 2s 7ms/step - loss: 0.1187 - accuracy: 0.9570\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 2s 7ms/step - loss: 0.1091 - accuracy: 0.9561\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 2s 7ms/step - loss: 0.0970 - accuracy: 0.9603\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 2s 7ms/step - loss: 0.0849 - accuracy: 0.9665\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 9)]          0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 62, 64)            2944      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 31, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 29, 128)           24704     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 28, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 26, 32)            12320     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 40,294\n",
            "Trainable params: 40,230\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LlRSQSg5x-G"
      },
      "source": [
        "###CNN MODEL ACCURACY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blVs1T8vtfQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56c6594-9b6e-4b25-c09c-8088ee525ac1"
      },
      "source": [
        "%time\n",
        "print(testX.shape,testy.shape)\n",
        "base_loss,base_accuracy=model.evaluate(testX,testy,batch_size=batch_size,verbose=1)\n",
        "\n",
        "cnn_file='CNN_Model.h5'\n",
        "  \n",
        "tf.keras.models.save_model(model, cnn_file, include_optimizer=False)\n",
        "print('model saved at ', cnn_file)\n",
        "#score,keras_file=evaluate_model(trainX,trainy,testX,testy)\n",
        "score=base_accuracy*100\n",
        "print('>{:f}'.format(score))\n",
        "print('>{:.2f}'.format(base_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
            "Wall time: 5.72 µs\n",
            "(2947, 128, 9) (2947, 6)\n",
            "93/93 [==============================] - 1s 4ms/step - loss: 0.1846 - accuracy: 0.9464\n",
            "model saved at  CNN_Model.h5\n",
            ">94.638616\n",
            ">0.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls6bWax459OF"
      },
      "source": [
        "##CNN MODEL SIZE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nyxtXsQA1Xg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8da05878-9a36-4b87-d185-1560bef406e3"
      },
      "source": [
        "%time\n",
        "predict=model.predict(testX)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
            "Wall time: 6.2 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzSgfywk3YX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d6fc096-c415-4c3d-c60a-41a550137869"
      },
      "source": [
        "cnn_model_size=get_zipped_model_size(cnn_file)\n",
        "print(\" SIze of my cnn model: {:.2f}MB\".format(cnn_model_size/1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " SIze of my cnn model: 152.12MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fswY0LP6vdj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86aa51c-012c-48b8-fb30-806f98587140"
      },
      "source": [
        "\n",
        "model=keras.models.load_model('CNN_Model.h5')\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "base_loss,base_accuracy=model.evaluate(testX,testy,batch_size=batch_size,verbose=0)\n",
        "print(base_loss,base_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "0.18462277948856354 0.9463861584663391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Vldri_p2iG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30081431-3e65-4a16-e3d4-5ce5802b6202"
      },
      "source": [
        "!pip install tensorflow_model_optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n",
            "\r\u001b[K     |██                              | 10kB 12.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 17.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40kB 14.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51kB 10.4MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81kB 10.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 112kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 122kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 133kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 143kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL7ACLxHvVa_"
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfjk8gd7Un-o"
      },
      "source": [
        "# %tensorboard --logdir={logdir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh4x5Etfq5_P"
      },
      "source": [
        "##Post-Training Quantization[FLOAT16] on CNN model (tflite model)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VrXvlcaQ2_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99642826-9400-4e48-e925-d224830880c9"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "quantized_cnn_model = converter.convert()\n",
        "\n",
        "quantized_cnn_tflite_file = 'quantized_cnn_model.tflite'\n",
        "\n",
        "with open(quantized_cnn_tflite_file, 'wb') as f:\n",
        "  f.write(quantized_cnn_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpt0wy049v/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqIQvI6xRMmb"
      },
      "source": [
        "##Size of post-quantized CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzdX8tOkRH8S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b477c6f3-f0c5-4398-aa1b-4ca679bdff64"
      },
      "source": [
        "quantized_cnn_model_size=get_zipped_model_size(quantized_cnn_tflite_file)\n",
        "print(\" Size of quantized cnn model: {:.2f}MB\".format(quantized_cnn_model_size/1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Size of quantized cnn model: 76.39MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pSN2jc8SRFM"
      },
      "source": [
        "##ACCURACY OF QUANTIZED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKylQdpqUhvw"
      },
      "source": [
        "def evaluate_model(interpreter):\n",
        "# Get input and output tensors.\n",
        "  input_details = interpreter.get_input_details()\n",
        "  output_details = interpreter.get_output_details()\n",
        "  print(input_details)\n",
        "  print(output_details)\n",
        "  print(\"== Input details ==\")\n",
        "  print(\"shape:\", input_details[0]['shape'])\n",
        "  print(\"type:\", input_details[0]['dtype'])\n",
        "  print(\"type:\", input_details[0]['index'])\n",
        "  print(\"\\n== Output details ==\")\n",
        "  print(\"shape:\", output_details[0]['shape'])\n",
        "  print(\"type:\", output_details[0]['dtype'])\n",
        "  print(\"type:\", output_details[0]['index'])\n",
        "\n",
        "\n",
        "\n",
        "  input_shape = input_details[0]['index']\n",
        "  output_shape = output_details[0]['index']\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction= []\n",
        "  print(testX.shape)\n",
        "  for i,test_data in enumerate(testX):\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "\n",
        "    test_data = np.expand_dims(test_data, axis=0).astype(np.float32)\n",
        "  \n",
        "    interpreter.set_tensor(input_shape, test_data)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.get_tensor(output_shape)\n",
        "    digit = np.argmax(output,axis=1)\n",
        "    prediction.append(digit)\n",
        "\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  \n",
        "  print('\\n')\n",
        "  prediction=np.array(prediction)\n",
        "  print(prediction.shape)\n",
        "  print(testy.shape)\n",
        "  labels=np.argmax(testy,axis=-1)\n",
        "  accuracy_count=0\n",
        "  for i in range(len(prediction)):\n",
        "    \n",
        "    if(prediction[i]==labels[i]).any():\n",
        "      accuracy_count+=1\n",
        "  \n",
        "  accuracy=(accuracy_count/len(prediction))*100\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92lKFioJUovC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cce8fd8-263c-48b4-b8d8-44500de4296e"
      },
      "source": [
        "\n",
        "interpreter=tf.lite.Interpreter(model_content=quantized_cnn_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "cnn_tflite_accuracy = evaluate_model(interpreter)\n",
        "\n",
        "print('Base TFLite test_accuracy:', cnn_tflite_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'name': 'input_1', 'index': 0, 'shape': array([  1, 128,   9], dtype=int32), 'shape_signature': array([ -1, 128,   9], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "[{'name': 'Identity', 'index': 38, 'shape': array([1, 6], dtype=int32), 'shape_signature': array([-1,  6], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "== Input details ==\n",
            "shape: [  1 128   9]\n",
            "type: <class 'numpy.float32'>\n",
            "type: 0\n",
            "\n",
            "== Output details ==\n",
            "shape: [1 6]\n",
            "type: <class 'numpy.float32'>\n",
            "type: 38\n",
            "(2947, 128, 9)\n",
            "\n",
            "\n",
            "(2947, 1)\n",
            "(2947, 6)\n",
            "Base TFLite test_accuracy: 94.63861554122836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmAm-qN3k-ra"
      },
      "source": [
        "#ADD QUANTIZATION AWARE TRAINING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzzBGFp926_N"
      },
      "source": [
        "#2.PRUNING CNN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_cbkqwJqLty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d007de4-a808-4cf2-bce2-25d8c6dd6897"
      },
      "source": [
        "prune_low_mag=tfmot.sparsity.keras.prune_low_magnitude\n",
        "batch_size=32\n",
        "epoch=5\n",
        "validation_split=0.3\n",
        "\n",
        "num=trainX.shape[0]*(1-validation_split)\n",
        "end_step=np.ceil(num / batch_size).astype(np.int32) * epoch\n",
        "pruning_params={\n",
        "    'pruning_schedule':tfmot.sparsity.keras.PolynomialDecay\n",
        "    (initial_sparsity=0.2,\n",
        "     final_sparsity=0.8,\n",
        "     begin_step=0,\n",
        "     end_step=end_step)\n",
        "}\n",
        "\n",
        "pruned_model=prune_low_mag(model,**pruning_params)\n",
        "\n",
        "pruned_model.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
        "\n",
        "pruned_model.summary()\n",
        "\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "pruned_model.fit(trainX, trainy,\n",
        "                  batch_size=batch_size, epochs=epoch, validation_split=validation_split,\n",
        "                  callbacks=callbacks)\n",
        "#Model accuracy\n",
        "model_for_pruning_loss, model_for_pruning_accuracy = pruned_model.evaluate(\n",
        "   testX, testy, verbose=0)\n",
        "print(model_for_pruning_loss,model_for_pruning_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 9)]          0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d ( (None, 62, 64)            5826      \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 31, 64)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (None, 29, 128)           49282     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 28, 128)           1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (None, 26, 32)            24610     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_global_a (None, 32)                1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_batch_no (None, 32)                129       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 6)                 392       \n",
            "=================================================================\n",
            "Total params: 80,242\n",
            "Trainable params: 40,230\n",
            "Non-trainable params: 40,012\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "  6/161 [>.............................] - ETA: 25s - loss: 0.0658 - accuracy: 0.9707WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0134s vs `on_train_batch_begin` time: 0.0416s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0134s vs `on_train_batch_begin` time: 0.0416s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0134s vs `on_train_batch_end` time: 0.0846s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0134s vs `on_train_batch_end` time: 0.0846s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "161/161 [==============================] - 8s 27ms/step - loss: 0.0758 - accuracy: 0.9675 - val_loss: 0.1249 - val_accuracy: 0.9637\n",
            "Epoch 2/5\n",
            "161/161 [==============================] - 3s 19ms/step - loss: 0.0760 - accuracy: 0.9654 - val_loss: 0.1657 - val_accuracy: 0.9456\n",
            "Epoch 3/5\n",
            "161/161 [==============================] - 3s 19ms/step - loss: 0.0827 - accuracy: 0.9692 - val_loss: 0.1352 - val_accuracy: 0.9506\n",
            "Epoch 4/5\n",
            "161/161 [==============================] - 3s 19ms/step - loss: 0.1001 - accuracy: 0.9571 - val_loss: 0.1406 - val_accuracy: 0.9624\n",
            "Epoch 5/5\n",
            "161/161 [==============================] - 3s 19ms/step - loss: 0.0697 - accuracy: 0.9740 - val_loss: 0.1340 - val_accuracy: 0.9615\n",
            "0.21185359358787537 0.9287410974502563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PrKkYSYVSA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cde5388-f581-4147-a2e3-2ebcc5f12299"
      },
      "source": [
        "#model size\n",
        "pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
        "pruned_cnn_file = ('prune_cnn.h5')\n",
        "tf.keras.models.save_model(pruned_model, pruned_cnn_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', pruned_cnn_file)\n",
        "pruned_cnn_model_size=get_zipped_model_size(pruned_cnn_file)\n",
        "print(\" SIze of pruned cnn model: {:.2f}MB\".format(pruned_cnn_model_size/1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: prune_cnn.h5\n",
            " SIze of pruned cnn model: 51.99MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_sqlQtVY4-C"
      },
      "source": [
        "#CONVERTING PRUNED MODEL TO TFLITE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjiR99cpY4Pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b1f367-c283-45db-e175-9933b52679a4"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
        "converter.experimental_new_converter = True\n",
        "\n",
        "cnn_pruned_model_tflite = converter.convert()\n",
        "\n",
        "cnn_pruned_tflite_file = 'cnn_pruned_model.tflite'\n",
        "\n",
        "with open(cnn_pruned_tflite_file, 'wb') as f:\n",
        "  f.write(cnn_pruned_model_tflite)\n",
        "\n",
        "print('Saved CNN TFLite model to:', cnn_pruned_tflite_file)\n",
        "\n",
        "\n",
        "interpreter=tf.lite.Interpreter(model_content=cnn_pruned_model_tflite)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "cnn_tflite_accuracy = evaluate_model(interpreter)\n",
        "\n",
        "print('Base TFLite test_accuracy:', cnn_tflite_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpeuohu0jl/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpeuohu0jl/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved CNN TFLite model to: cnn_pruned_model.tflite\n",
            "[{'name': 'input_1', 'index': 0, 'shape': array([  1, 128,   9], dtype=int32), 'shape_signature': array([ -1, 128,   9], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "[{'name': 'Identity', 'index': 38, 'shape': array([1, 6], dtype=int32), 'shape_signature': array([-1,  6], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "== Input details ==\n",
            "shape: [  1 128   9]\n",
            "type: <class 'numpy.float32'>\n",
            "type: 0\n",
            "\n",
            "== Output details ==\n",
            "shape: [1 6]\n",
            "type: <class 'numpy.float32'>\n",
            "type: 38\n",
            "(2947, 128, 9)\n",
            "\n",
            "\n",
            "(2947, 1)\n",
            "(2947, 6)\n",
            "Base TFLite test_accuracy: 92.87410926365796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9fmZ-kwZZ7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc2d1f4-3e93-422e-c029-e277812e1a68"
      },
      "source": [
        "cnn_pruned_model_size=get_zipped_model_size(cnn_pruned_tflite_file)\n",
        "print(\" Size of quantized cnn model: {:.2f}MB\".format(cnn_pruned_model_size/1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Size of quantized cnn model: 50.17MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tk86APZctEL"
      },
      "source": [
        "#POST-TRIANING QUANTIZATION ON PRUNED CNN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt6WNIrWcpEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4485ce2d-30c9-428a-c929-374b6052a2d9"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "quantized_pruned_cnn_model = converter.convert()\n",
        "\n",
        "quantized_pruned_cnn_tflite_file = 'quantized_pruned_cnn_model.tflite'\n",
        "\n",
        "with open(quantized_pruned_cnn_tflite_file, 'wb') as f:\n",
        "  f.write(quantized_pruned_cnn_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp69jzqheb/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp69jzqheb/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MthAb9zdhIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4066f9a-ccfa-4b2c-9f63-513becbe9079"
      },
      "source": [
        "quantized_pruned_cnn_model_size=get_zipped_model_size(quantized_pruned_cnn_tflite_file)\n",
        "print(\" Size of quantized cnn model: {:.2f}MB\".format(quantized_pruned_cnn_model_size/1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Size of quantized cnn model: 30.79MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MER7e23urqZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef5fe32-864a-484c-d261-98c085bef9d9"
      },
      "source": [
        "\n",
        "interpreter=tf.lite.Interpreter(model_content=quantized_pruned_cnn_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "quantized_pruned_cnn_model_accuracy = evaluate_model(interpreter)\n",
        "\n",
        "print('Quantized and Pruned CNN TFLite test_accuracy:', quantized_pruned_cnn_model_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'name': 'input_1', 'index': 0, 'shape': array([  1, 128,   9], dtype=int32), 'shape_signature': array([ -1, 128,   9], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "[{'name': 'Identity', 'index': 38, 'shape': array([1, 6], dtype=int32), 'shape_signature': array([-1,  6], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "== Input details ==\n",
            "shape: [  1 128   9]\n",
            "type: <class 'numpy.float32'>\n",
            "type: 0\n",
            "\n",
            "== Output details ==\n",
            "shape: [1 6]\n",
            "type: <class 'numpy.float32'>\n",
            "type: 38\n",
            "(2947, 128, 9)\n",
            "\n",
            "\n",
            "(2947, 1)\n",
            "(2947, 6)\n",
            "Quantized and Pruned CNN TFLite test_accuracy: 92.87410926365796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXd2B1T6yWfR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "10815991-cf59-4f86-efb3-11b16ef69c9f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "size=[cnn_model_size/1000,quantized_cnn_model_size/1000,pruned_cnn_model_size/1000,quantized_pruned_cnn_model_size/1000]\n",
        "label=['cnn','quant_cnn_tflite','prune_cnn','quant_pruned_cnn']\n",
        "\n",
        "print(\"Size of gzipped baseline Keras model: %.2f KB\" % (cnn_model_size/1000))\n",
        "print(\"Size of gzipped quantized Keras tflite model: %.2f KB\" % (quantized_cnn_model_size/1000))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f KB\" % (pruned_cnn_model_size/1000))\n",
        "print(\"Size of gzipped quantized and pruned TFlite model: %.2f KB\" % (quantized_pruned_cnn_model_size/1000))\n",
        "\n",
        "plt.bar(label,height=size)\n",
        "title_obj=plt.title('Size of baseline and pruned keras file')\n",
        "plt.setp(title_obj, color='w')\n",
        "plt.tick_params(axis='x', colors='white')\n",
        "plt.tick_params(axis='y', colors='white')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped baseline Keras model: 152.12 KB\n",
            "Size of gzipped quantized Keras tflite model: 76.39 KB\n",
            "Size of gzipped pruned Keras model: 51.99 KB\n",
            "Size of gzipped quantized and pruned TFlite model: 30.79 KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "868VAQgmzEDZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "d30368c1-ea14-498c-ffa8-9a942c29b4d8"
      },
      "source": [
        "model_accuracy=[score,cnn_tflite_accuracy,model_for_pruning_accuracy*100,quantized_pruned_cnn_model_accuracy]\n",
        "label=['keras_file','keras_tflite_file','pruned_keras_file','pruned_tflite_file']\n",
        "\n",
        "print(\"Accuracy baseline Keras model: %.2f bytes\" % (score))\n",
        "print(\"Accuracy Keras tflite model: %.2f bytes\" % (cnn_tflite_accuracy))\n",
        "print(\"Accuracy pruned Keras model: %.2f bytes\" % (model_for_pruning_accuracy*100))\n",
        "print(\"Accuracy pruned TFlite model: %.2f bytes\" % (quantized_pruned_cnn_model_accuracy))\n",
        "\n",
        "plt.bar(label,height=model_accuracy)\n",
        "title_obj=plt.title('Size of baseline and pruned keras file')\n",
        "plt.setp(title_obj, color='w')\n",
        "plt.tick_params(axis='x', colors='white')\n",
        "plt.tick_params(axis='y', colors='white')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy baseline Keras model: 94.64 bytes\n",
            "Accuracy Keras tflite model: 92.87 bytes\n",
            "Accuracy pruned Keras model: 92.87 bytes\n",
            "Accuracy pruned TFlite model: 92.87 bytes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "dark"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApGj7uWr6Ldy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}