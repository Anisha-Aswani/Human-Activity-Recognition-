{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNNmain.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1bc_ztKmcbzPQbGhitygZ8AeEUR2vM-bY","authorship_tag":"ABX9TyOsFHL/vhKqIkvFGICSa2Yb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1miUoB4oiUak"},"source":["#Importing Functions"]},{"cell_type":"code","metadata":{"id":"o_Hq0VUMvJx9","executionInfo":{"status":"ok","timestamp":1602823456428,"user_tz":420,"elapsed":2537,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}}},"source":["from numpy import mean\n","from numpy import std\n","from numpy import dstack\n","from pandas import read_csv\n","from scipy import ndimage\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers.convolutional import Conv1D,Conv2D\n","from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n","from keras.layers import BatchNormalization,ReLU,GlobalAveragePooling1D,MaxPooling1D,LSTM,TimeDistributed,GlobalAveragePooling2D\n","from keras.utils import to_categorical\n","from keras.models import save_model, load_model\n","from sklearn.preprocessing import StandardScaler\n","from keras.utils import to_categorical\n","from tensorflow.keras.utils import  plot_model\n","from keras.models import Model,save_model,load_model\n","from keras.layers import Input\n","from keras.layers.merge import concatenate\n","\n","from datetime import datetime\n","from packaging import version\n","\n","import os\n","import tempfile\n","import os\n","import tensorflow as tf\n","from tensorflow import expand_dims\n","from tensorflow import keras\n","%load_ext tensorboard"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"p8tRrh2Q2gnB","executionInfo":{"status":"ok","timestamp":1602823459713,"user_tz":420,"elapsed":5387,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"172806d4-fd83-4b33-dad2-e9df254cbab1","colab":{"base_uri":"https://localhost:8080/","height":220}},"source":["!pip install -U tensorboard_plugin_profile"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting tensorboard_plugin_profile\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/03/f4360c57a78c78fad63823b0abe65e589e98ec40ce9e41c549d46efcba75/tensorboard_plugin_profile-2.3.0-py3-none-any.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 4.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (1.15.0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (3.12.4)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (1.0.1)\n","Collecting gviz-api>=1.9.0\n","  Downloading https://files.pythonhosted.org/packages/8c/8f/c6f16235a16b3dc4efdcf34dbc93b3b6f678b88176dbd6a36c75d678888f/gviz_api-1.9.0-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard_plugin_profile) (50.3.0)\n","Installing collected packages: gviz-api, tensorboard-plugin-profile\n","Successfully installed gviz-api-1.9.0 tensorboard-plugin-profile-2.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"INpMNpCdimZr"},"source":["#Loading Dataset"]},{"cell_type":"code","metadata":{"id":"4vYcHaInEDoK","executionInfo":{"status":"ok","timestamp":1602823459715,"user_tz":420,"elapsed":4289,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}}},"source":["def load_file(filepath):\n","  dataframe=read_csv(filepath,header=None,delim_whitespace=True)\n","  return dataframe.values"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"r7akEplVIDyX","executionInfo":{"status":"ok","timestamp":1602823459717,"user_tz":420,"elapsed":3823,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}}},"source":["def load_group(filenames,prefix=''):\n","  loaded=list()\n","  for name in filenames:\n","    data=load_file(prefix+name)\n","    loaded.append(data)\n","  loaded=dstack(loaded)\n","  return loaded"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cKHYErTsIYac","executionInfo":{"status":"ok","timestamp":1602823459718,"user_tz":420,"elapsed":2226,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}}},"source":["def load_dataset_group(group,prefix=''):\n","  filepath=prefix+group+'/Inertial Signals/'\n","  filenames=list()\n","  filenames+=['total_acc_x_'+group+'.txt','total_acc_y_'+group+'.txt','total_acc_z_'+group+'.txt']\n","  filenames+=['body_acc_x_'+group+'.txt','body_acc_y_'+group+'.txt','body_acc_z_'+group+'.txt']\n","  filenames+=['body_gyro_x_'+group+'.txt','body_gyro_y_'+group+'.txt','body_gyro_z_'+group+'.txt']\n","  X=load_group(filenames,filepath)\n","  y=load_file(prefix+group+'/y_'+group+'.txt')\n","  return (X,y)\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"SuWfdQHuJt9f","executionInfo":{"status":"ok","timestamp":1602823466131,"user_tz":420,"elapsed":388,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}}},"source":["def load_dataset(prefix=''):\n","  trainX,trainy=load_dataset_group('train',prefix+'/content/drive/My Drive/Colab/MS Project/UCI HAR Dataset/UCI HAR Dataset/')\n","  print(trainX.shape,trainy.shape)\n","  testX,testy=load_dataset_group('test',prefix+'/content/drive/My Drive/Colab/MS Project/UCI HAR Dataset/UCI HAR Dataset/')\n","  print(testX.shape,testy.shape)\n","  trainy=trainy-1\n","  testy=testy-1\n","  trainy=to_categorical(trainy)\n","  testy=to_categorical(testy)\n","  print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n","  return trainX, trainy, testX, testy"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"C8Mtbf_PSH87","executionInfo":{"status":"ok","timestamp":1602823467095,"user_tz":420,"elapsed":380,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}}},"source":["def scale_data(trainX, testX):\n","\t# remove overlap\n","\tcut = int(trainX.shape[1] / 2)\n","\tlongX = trainX[:, -cut:, :]\n","\t# flatten windows\n","\tlongX = longX.reshape((longX.shape[0] * longX.shape[1], longX.shape[2]))\n","\t# flatten train and test\n","\tflatTrainX = trainX.reshape((trainX.shape[0] * trainX.shape[1], trainX.shape[2]))\n","\tflatTestX = testX.reshape((testX.shape[0] * testX.shape[1], testX.shape[2]))\n","\t# standardize\n","\n","\ts = StandardScaler()\n","\t\t# fit on training data\n","\ts.fit(longX)\n","\t\t# apply to training and test data\n","\tlongX = s.transform(longX)\n","\tflatTrainX = s.transform(flatTrainX)\n","\tflatTestX = s.transform(flatTestX)\n","\t# reshape\n","\tflatTrainX = flatTrainX.reshape((trainX.shape))\n","\tflatTestX = flatTestX.reshape((testX.shape))\n","\treturn flatTrainX, flatTestX"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2dow8qJO4myQ"},"source":["##Function for model size"]},{"cell_type":"code","metadata":{"id":"ytB8g1p74mEU","executionInfo":{"status":"ok","timestamp":1602823473706,"user_tz":420,"elapsed":398,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}}},"source":["def get_zipped_model_size(file):\n","  # Returns size of gzipped model, in bytes.\n","  import os\n","  import zipfile\n","\n","  zipped_file = file+'.zip'\n","  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n","    f.write(file)\n","\n","  return os.path.getsize(zipped_file)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LOWuN0ZroUDR"},"source":["##1. CNN MODEL\n"]},{"cell_type":"code","metadata":{"id":"N7BkQ1pYraEO","executionInfo":{"status":"ok","timestamp":1602823516161,"user_tz":420,"elapsed":39810,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"46b4fbdc-0888-487e-b7d7-fa6d16016315","colab":{"base_uri":"https://localhost:8080/","height":117}},"source":["trainX,trainy,testX,testy=load_dataset()\n","verbose,epochs,batch_size=1,500,32\n","n_timesteps,n_features,n_outputs=trainX.shape[1],trainX.shape[2],trainy.shape[1]\n","print('n step: ', n_timesteps)\n","print('features: ',n_features)\n","trainX,testX=scale_data(trainX,testX)\n","print(trainX.shape)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(7352, 128, 9) (7352, 1)\n","(2947, 128, 9) (2947, 1)\n","(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n","n step:  128\n","features:  9\n","(7352, 128, 9)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yciMN9WVMkpd","executionInfo":{"status":"ok","timestamp":1602823521906,"user_tz":420,"elapsed":44727,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}}},"source":["'''\n","inputs=keras.Input(shape=(n_timesteps,n_features))\n","\n","\n","conv_1=tf.keras.layers.Conv1D(filters=64,kernel_size=5,strides=2,activation='relu')(inputs)\n","maxpool_1=tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)(conv_1)\n","\n","conv_2=tf.keras.layers.Conv1D(filters=128,kernel_size=3,strides=1,activation='relu')(maxpool_1)\n","maxpool_2=tf.keras.layers.MaxPooling1D(pool_size=2,strides=1)(conv_2)\n","\n","conv_3=tf.keras.layers.Conv1D(filters=32,kernel_size=3,strides=1,activation='relu')(maxpool_2)\n","avg_pooling=tf.keras.layers.GlobalAveragePooling1D()(conv_3)\n","batch_norm=tf.keras.layers.BatchNormalization()(avg_pooling)\n","\n","output=tf.keras.layers.Dense(n_outputs,activation='softmax')(batch_norm)\n","model=tf.keras.Model(inputs=inputs,outputs=output)\n","'''\n","inputs=keras.Input(shape=(n_timesteps,n_features))\n","\n","\n","conv_1=tf.keras.layers.Conv1D(filters=64,kernel_size=5,strides=2,activation='relu')(inputs)\n","maxpool_1=tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)(conv_1)\n","\n","conv_2=tf.keras.layers.Conv1D(filters=128,kernel_size=3,strides=1,activation='relu')(maxpool_1)\n","maxpool_2=tf.keras.layers.MaxPooling1D(pool_size=2,strides=1)(conv_2)\n","\n","conv_3=tf.keras.layers.Conv1D(filters=32,kernel_size=3,strides=1,activation='relu')(maxpool_2)\n","avg_pooling=tf.keras.layers.GlobalAveragePooling1D()(conv_3)\n","batch_norm=tf.keras.layers.BatchNormalization()(avg_pooling)\n","\n","output=tf.keras.layers.Dense(n_outputs,activation='softmax')(batch_norm)\n","model=tf.keras.Model(inputs=inputs,outputs=output)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"UEENq8DHseVI","executionInfo":{"status":"ok","timestamp":1602823522300,"user_tz":420,"elapsed":44309,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}}},"source":["plot_model(model, show_shapes=True, to_file='/content/drive/My Drive/Colab/MS Project/My Model/CNN_Model.png')\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"W2vsYhbK2tvT","executionInfo":{"status":"ok","timestamp":1602824077463,"user_tz":420,"elapsed":598742,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"48efa05d-ba59-4710-8a0a-38de6025c564","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","\n","tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n","                                                 histogram_freq = 1,\n","                                                 )\n","\n","model.fit(trainX,trainy,epochs=epochs,batch_size=batch_size,verbose=verbose,callbacks=[tboard_callback])\n","model.summary()\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Epoch 1/500\n","  1/230 [..............................] - ETA: 0s - loss: 1.5445 - accuracy: 0.2500WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n","Instructions for updating:\n","use `tf.profiler.experimental.stop` instead.\n","  2/230 [..............................] - ETA: 6s - loss: 1.4064 - accuracy: 0.3594WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0122s vs `on_train_batch_end` time: 0.0426s). Check your callbacks.\n","230/230 [==============================] - 1s 5ms/step - loss: 0.2012 - accuracy: 0.9362\n","Epoch 2/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.1138 - accuracy: 0.9567\n","Epoch 3/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.1034 - accuracy: 0.9554\n","Epoch 4/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0898 - accuracy: 0.9606\n","Epoch 5/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0801 - accuracy: 0.9655\n","Epoch 6/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0751 - accuracy: 0.9672\n","Epoch 7/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0706 - accuracy: 0.9686\n","Epoch 8/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0694 - accuracy: 0.9702\n","Epoch 9/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0575 - accuracy: 0.9740\n","Epoch 10/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0546 - accuracy: 0.9744\n","Epoch 11/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0550 - accuracy: 0.9728\n","Epoch 12/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0544 - accuracy: 0.9766\n","Epoch 13/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0416 - accuracy: 0.9829\n","Epoch 14/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0456 - accuracy: 0.9792\n","Epoch 15/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0441 - accuracy: 0.9805\n","Epoch 16/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0344 - accuracy: 0.9853\n","Epoch 17/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9852\n","Epoch 18/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0447 - accuracy: 0.9789\n","Epoch 19/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0318 - accuracy: 0.9872\n","Epoch 20/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0320 - accuracy: 0.9879\n","Epoch 21/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0283 - accuracy: 0.9880\n","Epoch 22/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0233 - accuracy: 0.9912\n","Epoch 23/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0249 - accuracy: 0.9895\n","Epoch 24/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0276 - accuracy: 0.9886\n","Epoch 25/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0256 - accuracy: 0.9903\n","Epoch 26/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9917\n","Epoch 27/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0208 - accuracy: 0.9914\n","Epoch 28/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.9948\n","Epoch 29/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0140 - accuracy: 0.9943\n","Epoch 30/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0165 - accuracy: 0.9947\n","Epoch 31/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0127 - accuracy: 0.9944\n","Epoch 32/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0155 - accuracy: 0.9940\n","Epoch 33/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0147 - accuracy: 0.9944\n","Epoch 34/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0182 - accuracy: 0.9927\n","Epoch 35/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0128 - accuracy: 0.9955\n","Epoch 36/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9969\n","Epoch 37/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0165 - accuracy: 0.9951\n","Epoch 38/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0157 - accuracy: 0.9943\n","Epoch 39/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.9973\n","Epoch 40/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9961\n","Epoch 41/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0178 - accuracy: 0.9931\n","Epoch 42/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9967\n","Epoch 43/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.9961\n","Epoch 44/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0189 - accuracy: 0.9936\n","Epoch 45/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9966\n","Epoch 46/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9993\n","Epoch 47/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.9984\n","Epoch 48/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9992\n","Epoch 49/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9967\n","Epoch 50/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0104 - accuracy: 0.9956\n","Epoch 51/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9959\n","Epoch 52/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0081 - accuracy: 0.9971\n","Epoch 53/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0020 - accuracy: 0.9995\n","Epoch 54/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.9985\n","Epoch 55/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9989\n","Epoch 56/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0133 - accuracy: 0.9958\n","Epoch 57/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9976\n","Epoch 58/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0156 - accuracy: 0.9963\n","Epoch 59/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0152 - accuracy: 0.9951\n","Epoch 60/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9995\n","Epoch 61/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.9988\n","Epoch 62/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0137 - accuracy: 0.9948\n","Epoch 63/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9989\n","Epoch 64/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9992\n","Epoch 65/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9990\n","Epoch 66/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0171 - accuracy: 0.9946\n","Epoch 67/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9980\n","Epoch 68/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 0.9997\n","Epoch 69/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9965\n","Epoch 70/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0143 - accuracy: 0.9946\n","Epoch 71/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0087 - accuracy: 0.9970\n","Epoch 72/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9984\n","Epoch 73/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0066 - accuracy: 0.9977\n","Epoch 74/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 0.9997\n","Epoch 75/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 0.9996\n","Epoch 76/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.9986\n","Epoch 77/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.9982\n","Epoch 78/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.2640e-04 - accuracy: 0.9999\n","Epoch 79/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9993\n","Epoch 80/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9981\n","Epoch 81/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9970\n","Epoch 82/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0144 - accuracy: 0.9955\n","Epoch 83/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9995\n","Epoch 84/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9995\n","Epoch 85/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9976\n","Epoch 86/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.9967\n","Epoch 87/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9989\n","Epoch 88/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.7198e-04 - accuracy: 1.0000\n","Epoch 89/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.2666e-04 - accuracy: 1.0000\n","Epoch 90/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.4922e-04 - accuracy: 1.0000\n","Epoch 91/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.1766e-04 - accuracy: 1.0000\n","Epoch 92/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0114 - accuracy: 0.9967\n","Epoch 93/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9984\n","Epoch 94/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.9981\n","Epoch 95/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9995\n","Epoch 96/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9992\n","Epoch 97/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9988\n","Epoch 98/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0073 - accuracy: 0.9969\n","Epoch 99/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9976\n","Epoch 100/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9971\n","Epoch 101/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9993\n","Epoch 102/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.3402e-04 - accuracy: 0.9999\n","Epoch 103/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.9679e-04 - accuracy: 1.0000\n","Epoch 104/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.6294e-04 - accuracy: 1.0000\n","Epoch 105/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.2834e-04 - accuracy: 1.0000\n","Epoch 106/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.5469e-04 - accuracy: 1.0000\n","Epoch 107/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9984\n","Epoch 108/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0107 - accuracy: 0.9965\n","Epoch 109/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9996\n","Epoch 110/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9958\n","Epoch 111/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9978\n","Epoch 112/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 113/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.0075e-04 - accuracy: 1.0000\n","Epoch 114/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.5332e-04 - accuracy: 1.0000\n","Epoch 115/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.6616e-04 - accuracy: 1.0000\n","Epoch 116/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.1834e-04 - accuracy: 1.0000\n","Epoch 117/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.5984e-04 - accuracy: 1.0000\n","Epoch 118/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4139e-04 - accuracy: 1.0000\n","Epoch 119/500\n","230/230 [==============================] - 1s 5ms/step - loss: 9.0369e-05 - accuracy: 1.0000\n","Epoch 120/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.1323e-04 - accuracy: 1.0000\n","Epoch 121/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.2840e-04 - accuracy: 1.0000\n","Epoch 122/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.3255e-04 - accuracy: 1.0000\n","Epoch 123/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.9971\n","Epoch 124/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0294 - accuracy: 0.9921\n","Epoch 125/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0066 - accuracy: 0.9977\n","Epoch 126/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 127/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.3805e-04 - accuracy: 0.9999\n","Epoch 128/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9992\n","Epoch 129/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9981\n","Epoch 130/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9989\n","Epoch 131/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.3324e-04 - accuracy: 0.9999\n","Epoch 132/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9993\n","Epoch 133/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.1143e-04 - accuracy: 1.0000\n","Epoch 134/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9990\n","Epoch 135/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9996\n","Epoch 136/500\n","230/230 [==============================] - 1s 4ms/step - loss: 6.3001e-04 - accuracy: 0.9999\n","Epoch 137/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0127 - accuracy: 0.9965\n","Epoch 138/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9984\n","Epoch 139/500\n","230/230 [==============================] - 1s 4ms/step - loss: 9.5496e-04 - accuracy: 0.9996\n","Epoch 140/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 0.9997\n","Epoch 141/500\n","230/230 [==============================] - 1s 4ms/step - loss: 2.6088e-04 - accuracy: 1.0000\n","Epoch 142/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9992\n","Epoch 143/500\n","230/230 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9990\n","Epoch 144/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n","Epoch 145/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0146 - accuracy: 0.9965\n","Epoch 146/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.3019e-04 - accuracy: 0.9999\n","Epoch 147/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.5310e-04 - accuracy: 1.0000\n","Epoch 148/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.6523e-04 - accuracy: 1.0000\n","Epoch 149/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9995\n","Epoch 150/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.4004e-04 - accuracy: 1.0000\n","Epoch 151/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.5686e-04 - accuracy: 0.9999\n","Epoch 152/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9988\n","Epoch 153/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.9971\n","Epoch 154/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9981\n","Epoch 155/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 156/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.7851e-04 - accuracy: 1.0000\n","Epoch 157/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.2521e-04 - accuracy: 0.9997\n","Epoch 158/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.9872e-04 - accuracy: 1.0000\n","Epoch 159/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.2600e-04 - accuracy: 1.0000\n","Epoch 160/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.0349e-04 - accuracy: 1.0000\n","Epoch 161/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.1458e-05 - accuracy: 1.0000\n","Epoch 162/500\n","230/230 [==============================] - 1s 4ms/step - loss: 5.7216e-05 - accuracy: 1.0000\n","Epoch 163/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.7531e-04 - accuracy: 0.9999\n","Epoch 164/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0153 - accuracy: 0.9947\n","Epoch 165/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 0.9997\n","Epoch 166/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 0.9997\n","Epoch 167/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.2531e-04 - accuracy: 1.0000\n","Epoch 168/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9995\n","Epoch 169/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.2489e-04 - accuracy: 1.0000\n","Epoch 170/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.3400e-04 - accuracy: 1.0000\n","Epoch 171/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9992\n","Epoch 172/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9981\n","Epoch 173/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 0.9988\n","Epoch 174/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9985\n","Epoch 175/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.6561e-04 - accuracy: 1.0000\n","Epoch 176/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7583e-04 - accuracy: 1.0000\n","Epoch 177/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.3044e-04 - accuracy: 0.9997\n","Epoch 178/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.9980\n","Epoch 179/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 0.9986\n","Epoch 180/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 0.9989\n","Epoch 181/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.5812e-04 - accuracy: 0.9999\n","Epoch 182/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.7156e-04 - accuracy: 1.0000\n","Epoch 183/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.3550e-04 - accuracy: 1.0000\n","Epoch 184/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.3888e-04 - accuracy: 1.0000\n","Epoch 185/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.7864e-04 - accuracy: 0.9999\n","Epoch 186/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0053 - accuracy: 0.9978\n","Epoch 187/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0117 - accuracy: 0.9961\n","Epoch 188/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9993\n","Epoch 189/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 0.9990\n","Epoch 190/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0020 - accuracy: 0.9995\n","Epoch 191/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 0.9989\n","Epoch 192/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 0.9992\n","Epoch 193/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9988\n","Epoch 194/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9995\n","Epoch 195/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.0896e-04 - accuracy: 0.9996\n","Epoch 196/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.3900e-04 - accuracy: 1.0000\n","Epoch 197/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.3345e-05 - accuracy: 1.0000\n","Epoch 198/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.7018e-05 - accuracy: 1.0000\n","Epoch 199/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.0487e-04 - accuracy: 1.0000\n","Epoch 200/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.3320e-05 - accuracy: 1.0000\n","Epoch 201/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.3445e-05 - accuracy: 1.0000\n","Epoch 202/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.0334e-04 - accuracy: 1.0000\n","Epoch 203/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.9986\n","Epoch 204/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9981\n","Epoch 205/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9978\n","Epoch 206/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.7948e-04 - accuracy: 0.9996\n","Epoch 207/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.3739e-04 - accuracy: 1.0000\n","Epoch 208/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.1726e-04 - accuracy: 0.9999\n","Epoch 209/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9996\n","Epoch 210/500\n","230/230 [==============================] - 1s 5ms/step - loss: 9.2074e-04 - accuracy: 0.9999\n","Epoch 211/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.1930e-04 - accuracy: 0.9997\n","Epoch 212/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.5249e-04 - accuracy: 0.9997\n","Epoch 213/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0139 - accuracy: 0.9950\n","Epoch 214/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9993\n","Epoch 215/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.6187e-04 - accuracy: 1.0000\n","Epoch 216/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7814e-04 - accuracy: 1.0000\n","Epoch 217/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9993\n","Epoch 218/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.8312e-04 - accuracy: 1.0000\n","Epoch 219/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.9254e-04 - accuracy: 0.9999\n","Epoch 220/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.4557e-04 - accuracy: 1.0000\n","Epoch 221/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.2415e-04 - accuracy: 1.0000\n","Epoch 222/500\n","230/230 [==============================] - 1s 5ms/step - loss: 9.3339e-05 - accuracy: 1.0000\n","Epoch 223/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.1215e-04 - accuracy: 1.0000\n","Epoch 224/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.2909e-04 - accuracy: 1.0000\n","Epoch 225/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4346e-04 - accuracy: 1.0000\n","Epoch 226/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9995\n","Epoch 227/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0194 - accuracy: 0.9950\n","Epoch 228/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 0.9992\n","Epoch 229/500\n","230/230 [==============================] - 1s 5ms/step - loss: 9.5648e-04 - accuracy: 0.9997\n","Epoch 230/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.2181e-04 - accuracy: 0.9999\n","Epoch 231/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n","Epoch 232/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.4537e-04 - accuracy: 1.0000\n","Epoch 233/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.8422e-04 - accuracy: 1.0000\n","Epoch 234/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.9338e-05 - accuracy: 1.0000\n","Epoch 235/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.5252e-04 - accuracy: 1.0000\n","Epoch 236/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.2802e-05 - accuracy: 1.0000\n","Epoch 237/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.9873e-05 - accuracy: 1.0000\n","Epoch 238/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7142e-04 - accuracy: 1.0000\n","Epoch 239/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.9837e-05 - accuracy: 1.0000\n","Epoch 240/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.6011e-05 - accuracy: 1.0000\n","Epoch 241/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.0693e-04 - accuracy: 0.9999\n","Epoch 242/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9971\n","Epoch 243/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9985\n","Epoch 244/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 245/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9995\n","Epoch 246/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.6950e-04 - accuracy: 0.9997\n","Epoch 247/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.9978\n","Epoch 248/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9997\n","Epoch 249/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.8321e-04 - accuracy: 1.0000\n","Epoch 250/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.5814e-04 - accuracy: 1.0000\n","Epoch 251/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 0.9993\n","Epoch 252/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9993\n","Epoch 253/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.9667e-04 - accuracy: 1.0000\n","Epoch 254/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7158e-04 - accuracy: 1.0000\n","Epoch 255/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 0.9995\n","Epoch 256/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9996\n","Epoch 257/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.3418e-04 - accuracy: 1.0000\n","Epoch 258/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.2711e-05 - accuracy: 1.0000\n","Epoch 259/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.4104e-05 - accuracy: 1.0000\n","Epoch 260/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.5346e-05 - accuracy: 1.0000\n","Epoch 261/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.8668e-05 - accuracy: 1.0000\n","Epoch 262/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.1322e-04 - accuracy: 0.9996\n","Epoch 263/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9976\n","Epoch 264/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9985\n","Epoch 265/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.7617e-04 - accuracy: 0.9999\n","Epoch 266/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9990\n","Epoch 267/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4306e-04 - accuracy: 1.0000\n","Epoch 268/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9995\n","Epoch 269/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4153e-04 - accuracy: 1.0000\n","Epoch 270/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7688e-04 - accuracy: 1.0000\n","Epoch 271/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.7922e-05 - accuracy: 1.0000\n","Epoch 272/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.5988e-04 - accuracy: 1.0000\n","Epoch 273/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9997\n","Epoch 274/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7093e-04 - accuracy: 1.0000\n","Epoch 275/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.2695e-05 - accuracy: 1.0000\n","Epoch 276/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.9214e-05 - accuracy: 1.0000\n","Epoch 277/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.0944e-04 - accuracy: 1.0000\n","Epoch 278/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9999\n","Epoch 279/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 0.9992\n","Epoch 280/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0142 - accuracy: 0.9959\n","Epoch 281/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 0.9993\n","Epoch 282/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.8751e-04 - accuracy: 0.9997\n","Epoch 283/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 0.9997\n","Epoch 284/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9995\n","Epoch 285/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.9373e-04 - accuracy: 1.0000\n","Epoch 286/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.1944e-04 - accuracy: 1.0000\n","Epoch 287/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.4166e-05 - accuracy: 1.0000\n","Epoch 288/500\n","230/230 [==============================] - 1s 5ms/step - loss: 9.0414e-05 - accuracy: 1.0000\n","Epoch 289/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.8166e-05 - accuracy: 1.0000\n","Epoch 290/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.0445e-04 - accuracy: 1.0000\n","Epoch 291/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9989\n","Epoch 292/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9997\n","Epoch 293/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9996\n","Epoch 294/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9992\n","Epoch 295/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.5762e-04 - accuracy: 1.0000\n","Epoch 296/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.4096e-04 - accuracy: 0.9997\n","Epoch 297/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.8041e-04 - accuracy: 1.0000\n","Epoch 298/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.0030e-04 - accuracy: 0.9999\n","Epoch 299/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 0.9996\n","Epoch 300/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.2795e-05 - accuracy: 1.0000\n","Epoch 301/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.1833e-05 - accuracy: 1.0000\n","Epoch 302/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.4580e-05 - accuracy: 1.0000\n","Epoch 303/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.3648e-04 - accuracy: 0.9999\n","Epoch 304/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.2484e-04 - accuracy: 1.0000\n","Epoch 305/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9992\n","Epoch 306/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9976\n","Epoch 307/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9988\n","Epoch 308/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.8692e-04 - accuracy: 1.0000\n","Epoch 309/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.0684e-04 - accuracy: 1.0000\n","Epoch 310/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.5841e-04 - accuracy: 1.0000\n","Epoch 311/500\n","230/230 [==============================] - 1s 5ms/step - loss: 9.0369e-05 - accuracy: 1.0000\n","Epoch 312/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.3585e-05 - accuracy: 1.0000\n","Epoch 313/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.8225e-05 - accuracy: 1.0000\n","Epoch 314/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.7466e-05 - accuracy: 1.0000\n","Epoch 315/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.1032e-05 - accuracy: 1.0000\n","Epoch 316/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.1187e-05 - accuracy: 1.0000\n","Epoch 317/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.9019e-05 - accuracy: 1.0000\n","Epoch 318/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.3689e-05 - accuracy: 1.0000\n","Epoch 319/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.6261e-05 - accuracy: 1.0000\n","Epoch 320/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7060e-05 - accuracy: 1.0000\n","Epoch 321/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7518e-05 - accuracy: 1.0000\n","Epoch 322/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.9764e-05 - accuracy: 1.0000\n","Epoch 323/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.1381e-05 - accuracy: 1.0000\n","Epoch 324/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.6448e-05 - accuracy: 1.0000\n","Epoch 325/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.9993\n","Epoch 326/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.9971\n","Epoch 327/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9993\n","Epoch 328/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.9992\n","Epoch 329/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.8678e-04 - accuracy: 0.9999\n","Epoch 330/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4170e-04 - accuracy: 1.0000\n","Epoch 331/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.6166e-04 - accuracy: 1.0000\n","Epoch 332/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.9004e-05 - accuracy: 1.0000\n","Epoch 333/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.7261e-05 - accuracy: 1.0000\n","Epoch 334/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.6153e-05 - accuracy: 1.0000\n","Epoch 335/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.3963e-04 - accuracy: 1.0000\n","Epoch 336/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9990\n","Epoch 337/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.5167e-04 - accuracy: 1.0000\n","Epoch 338/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.7679e-05 - accuracy: 1.0000\n","Epoch 339/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4132e-04 - accuracy: 1.0000\n","Epoch 340/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0110 - accuracy: 0.9970\n","Epoch 341/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9993\n","Epoch 342/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.6434e-04 - accuracy: 0.9999\n","Epoch 343/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9995\n","Epoch 344/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9997\n","Epoch 345/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.2955e-04 - accuracy: 1.0000\n","Epoch 346/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.1120e-04 - accuracy: 0.9999\n","Epoch 347/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9997\n","Epoch 348/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9974\n","Epoch 349/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.0910e-04 - accuracy: 1.0000\n","Epoch 350/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.0626e-04 - accuracy: 1.0000\n","Epoch 351/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.2541e-04 - accuracy: 1.0000\n","Epoch 352/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.7952e-04 - accuracy: 0.9999\n","Epoch 353/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9997\n","Epoch 354/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.7457e-05 - accuracy: 1.0000\n","Epoch 355/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.0235e-05 - accuracy: 1.0000\n","Epoch 356/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.9630e-05 - accuracy: 1.0000\n","Epoch 357/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4360e-04 - accuracy: 1.0000\n","Epoch 358/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.2448e-04 - accuracy: 1.0000\n","Epoch 359/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.6214e-05 - accuracy: 1.0000\n","Epoch 360/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.1609e-05 - accuracy: 1.0000\n","Epoch 361/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.4359e-04 - accuracy: 0.9997\n","Epoch 362/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0138 - accuracy: 0.9962\n","Epoch 363/500\n","230/230 [==============================] - 1s 5ms/step - loss: 9.4420e-04 - accuracy: 0.9999\n","Epoch 364/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.6250e-04 - accuracy: 1.0000\n","Epoch 365/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9999\n","Epoch 366/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.3478e-04 - accuracy: 1.0000\n","Epoch 367/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.1331e-05 - accuracy: 1.0000\n","Epoch 368/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 0.9989\n","Epoch 369/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.9685e-04 - accuracy: 0.9999\n","Epoch 370/500\n","230/230 [==============================] - 1s 5ms/step - loss: 9.4109e-05 - accuracy: 1.0000\n","Epoch 371/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.0248e-05 - accuracy: 1.0000\n","Epoch 372/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.2161e-05 - accuracy: 1.0000\n","Epoch 373/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.2795e-05 - accuracy: 1.0000\n","Epoch 374/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.4728e-05 - accuracy: 1.0000\n","Epoch 375/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4526e-05 - accuracy: 1.0000\n","Epoch 376/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.5505e-05 - accuracy: 1.0000\n","Epoch 377/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.4684e-05 - accuracy: 1.0000\n","Epoch 378/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.3470e-05 - accuracy: 1.0000\n","Epoch 379/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.2981e-05 - accuracy: 1.0000\n","Epoch 380/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.4346e-05 - accuracy: 1.0000\n","Epoch 381/500\n","230/230 [==============================] - 1s 5ms/step - loss: 9.9959e-06 - accuracy: 1.0000\n","Epoch 382/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.6233e-05 - accuracy: 1.0000\n","Epoch 383/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.1114e-05 - accuracy: 1.0000\n","Epoch 384/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9993\n","Epoch 385/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9970\n","Epoch 386/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9993\n","Epoch 387/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.6460e-04 - accuracy: 0.9999\n","Epoch 388/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7561e-04 - accuracy: 1.0000\n","Epoch 389/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.9343e-05 - accuracy: 1.0000\n","Epoch 390/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.2235e-04 - accuracy: 1.0000\n","Epoch 391/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.7044e-05 - accuracy: 1.0000\n","Epoch 392/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4547e-04 - accuracy: 1.0000\n","Epoch 393/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.0886e-04 - accuracy: 0.9999\n","Epoch 394/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9995\n","Epoch 395/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4460e-04 - accuracy: 1.0000\n","Epoch 396/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.8590e-04 - accuracy: 1.0000\n","Epoch 397/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.1124e-04 - accuracy: 1.0000\n","Epoch 398/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.0923e-05 - accuracy: 1.0000\n","Epoch 399/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.4192e-05 - accuracy: 1.0000\n","Epoch 400/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.5446e-05 - accuracy: 1.0000\n","Epoch 401/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.8215e-05 - accuracy: 1.0000\n","Epoch 402/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.3825e-05 - accuracy: 1.0000\n","Epoch 403/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.3362e-05 - accuracy: 1.0000\n","Epoch 404/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.4983e-06 - accuracy: 1.0000\n","Epoch 405/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.1935e-05 - accuracy: 1.0000\n","Epoch 406/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0158 - accuracy: 0.9966\n","Epoch 407/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9992\n","Epoch 408/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.5887e-04 - accuracy: 1.0000\n","Epoch 409/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9997\n","Epoch 410/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.6910e-04 - accuracy: 1.0000\n","Epoch 411/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.2613e-04 - accuracy: 0.9999\n","Epoch 412/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.2473e-05 - accuracy: 1.0000\n","Epoch 413/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.3838e-04 - accuracy: 1.0000\n","Epoch 414/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.2999e-05 - accuracy: 1.0000\n","Epoch 415/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.1660e-05 - accuracy: 1.0000\n","Epoch 416/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.9882e-05 - accuracy: 1.0000\n","Epoch 417/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.6449e-05 - accuracy: 1.0000\n","Epoch 418/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.9187e-05 - accuracy: 1.0000\n","Epoch 419/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.6468e-05 - accuracy: 1.0000\n","Epoch 420/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.9531e-05 - accuracy: 1.0000\n","Epoch 421/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.9967\n","Epoch 422/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9992\n","Epoch 423/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 0.9995\n","Epoch 424/500\n","230/230 [==============================] - 1s 5ms/step - loss: 7.3807e-04 - accuracy: 0.9997\n","Epoch 425/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.1177e-04 - accuracy: 1.0000\n","Epoch 426/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7088e-04 - accuracy: 1.0000\n","Epoch 427/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.2410e-04 - accuracy: 1.0000\n","Epoch 428/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 0.9997\n","Epoch 429/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.5485e-04 - accuracy: 1.0000\n","Epoch 430/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.8913e-05 - accuracy: 1.0000\n","Epoch 431/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.0413e-05 - accuracy: 1.0000\n","Epoch 432/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.4474e-05 - accuracy: 1.0000\n","Epoch 433/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.7063e-05 - accuracy: 1.0000\n","Epoch 434/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.6274e-05 - accuracy: 1.0000\n","Epoch 435/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.2151e-05 - accuracy: 1.0000\n","Epoch 436/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.9138e-05 - accuracy: 1.0000\n","Epoch 437/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9980\n","Epoch 438/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.6556e-04 - accuracy: 0.9999\n","Epoch 439/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.0886e-04 - accuracy: 1.0000\n","Epoch 440/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.2301e-04 - accuracy: 1.0000\n","Epoch 441/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.1208e-04 - accuracy: 1.0000\n","Epoch 442/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.6351e-04 - accuracy: 1.0000\n","Epoch 443/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.0495e-05 - accuracy: 1.0000\n","Epoch 444/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.0022e-05 - accuracy: 1.0000\n","Epoch 445/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.3027e-05 - accuracy: 1.0000\n","Epoch 446/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7174e-05 - accuracy: 1.0000\n","Epoch 447/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.5982e-05 - accuracy: 1.0000\n","Epoch 448/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.6494e-05 - accuracy: 1.0000\n","Epoch 449/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9981\n","Epoch 450/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9973\n","Epoch 451/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.3823e-04 - accuracy: 0.9999\n","Epoch 452/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.6525e-04 - accuracy: 1.0000\n","Epoch 453/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.6181e-04 - accuracy: 1.0000\n","Epoch 454/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9990\n","Epoch 455/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9995\n","Epoch 456/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.2428e-04 - accuracy: 1.0000\n","Epoch 457/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7507e-04 - accuracy: 1.0000\n","Epoch 458/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.6651e-04 - accuracy: 0.9999\n","Epoch 459/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.5269e-04 - accuracy: 0.9999\n","Epoch 460/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.8988e-04 - accuracy: 0.9996\n","Epoch 461/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9988\n","Epoch 462/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.0448e-04 - accuracy: 1.0000\n","Epoch 463/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.9403e-04 - accuracy: 1.0000\n","Epoch 464/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.4617e-04 - accuracy: 0.9999\n","Epoch 465/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4331e-04 - accuracy: 1.0000\n","Epoch 466/500\n","230/230 [==============================] - 1s 5ms/step - loss: 9.4901e-05 - accuracy: 1.0000\n","Epoch 467/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.0239e-04 - accuracy: 1.0000\n","Epoch 468/500\n","230/230 [==============================] - 1s 5ms/step - loss: 6.6582e-05 - accuracy: 1.0000\n","Epoch 469/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.2737e-05 - accuracy: 1.0000\n","Epoch 470/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 0.9995\n","Epoch 471/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9997\n","Epoch 472/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.1466e-04 - accuracy: 0.9999\n","Epoch 473/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.9593e-05 - accuracy: 1.0000\n","Epoch 474/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.7449e-05 - accuracy: 1.0000\n","Epoch 475/500\n","230/230 [==============================] - 1s 5ms/step - loss: 5.9087e-04 - accuracy: 0.9997\n","Epoch 476/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9980\n","Epoch 477/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9990\n","Epoch 478/500\n","230/230 [==============================] - 1s 5ms/step - loss: 9.7529e-04 - accuracy: 0.9999\n","Epoch 479/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.8131e-04 - accuracy: 1.0000\n","Epoch 480/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.2896e-04 - accuracy: 1.0000\n","Epoch 481/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9990\n","Epoch 482/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.2857e-04 - accuracy: 1.0000\n","Epoch 483/500\n","230/230 [==============================] - 1s 5ms/step - loss: 8.7535e-05 - accuracy: 1.0000\n","Epoch 484/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.2122e-05 - accuracy: 1.0000\n","Epoch 485/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.5635e-05 - accuracy: 1.0000\n","Epoch 486/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9992\n","Epoch 487/500\n","230/230 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9990\n","Epoch 488/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4423e-04 - accuracy: 1.0000\n","Epoch 489/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.0198e-04 - accuracy: 1.0000\n","Epoch 490/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.8337e-04 - accuracy: 0.9999\n","Epoch 491/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7967e-04 - accuracy: 1.0000\n","Epoch 492/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.4651e-05 - accuracy: 1.0000\n","Epoch 493/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.9722e-05 - accuracy: 1.0000\n","Epoch 494/500\n","230/230 [==============================] - 1s 5ms/step - loss: 4.1630e-05 - accuracy: 1.0000\n","Epoch 495/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.8773e-05 - accuracy: 1.0000\n","Epoch 496/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.3570e-05 - accuracy: 1.0000\n","Epoch 497/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.7607e-05 - accuracy: 1.0000\n","Epoch 498/500\n","230/230 [==============================] - 1s 5ms/step - loss: 2.2542e-05 - accuracy: 1.0000\n","Epoch 499/500\n","230/230 [==============================] - 1s 5ms/step - loss: 1.4849e-04 - accuracy: 0.9999\n","Epoch 500/500\n","230/230 [==============================] - 1s 5ms/step - loss: 3.4852e-05 - accuracy: 1.0000\n","Model: \"functional_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 128, 9)]          0         \n","_________________________________________________________________\n","conv1d (Conv1D)              (None, 62, 64)            2944      \n","_________________________________________________________________\n","max_pooling1d (MaxPooling1D) (None, 31, 64)            0         \n","_________________________________________________________________\n","conv1d_1 (Conv1D)            (None, 29, 128)           24704     \n","_________________________________________________________________\n","max_pooling1d_1 (MaxPooling1 (None, 28, 128)           0         \n","_________________________________________________________________\n","conv1d_2 (Conv1D)            (None, 26, 32)            12320     \n","_________________________________________________________________\n","global_average_pooling1d (Gl (None, 32)                0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 32)                128       \n","_________________________________________________________________\n","dense (Dense)                (None, 6)                 198       \n","=================================================================\n","Total params: 40,294\n","Trainable params: 40,230\n","Non-trainable params: 64\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1LlRSQSg5x-G"},"source":["###CNN MODEL ACCURACY"]},{"cell_type":"code","metadata":{"id":"blVs1T8vtfQD","executionInfo":{"status":"ok","timestamp":1602824078111,"user_tz":420,"elapsed":598091,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"8af23597-7ea7-4beb-b7ea-3a8049a9d5a1","colab":{"base_uri":"https://localhost:8080/","height":133}},"source":["%time\n","print(testX.shape,testy.shape)\n","base_loss,base_accuracy=model.evaluate(testX,testy,batch_size=batch_size,verbose=1)\n","\n","cnn_file='/content/drive/My Drive/Colab/MS Project/My Model/CNN_Model.h5'\n","  \n","tf.keras.models.save_model(model, cnn_file, include_optimizer=False)\n","print('model saved at ', cnn_file)\n","#score,keras_file=evaluate_model(trainX,trainy,testX,testy)\n","score=base_accuracy*100\n","print('>{:f}'.format(score))\n","print('>{:.2f}'.format(base_loss))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n","Wall time: 4.53 µs\n","(2947, 128, 9) (2947, 6)\n","93/93 [==============================] - 0s 3ms/step - loss: 0.3831 - accuracy: 0.9460\n","model saved at  /content/drive/My Drive/Colab/MS Project/My Model/CNN_Model.h5\n",">94.604683\n",">0.38\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ls6bWax459OF"},"source":["##CNN MODEL SIZE"]},{"cell_type":"code","metadata":{"id":"7nyxtXsQA1Xg","executionInfo":{"status":"ok","timestamp":1602824078251,"user_tz":420,"elapsed":596792,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"1db44205-e996-4c6a-d756-fe05bdb9d943","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["%time\n","predict=model.predict(testX)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n","Wall time: 7.39 µs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mzSgfywk3YX-","executionInfo":{"status":"ok","timestamp":1602824078252,"user_tz":420,"elapsed":596324,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"e2d783f7-7ec8-4c2e-ecf4-56eaa0db5a74","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["cnn_model_size=get_zipped_model_size(cnn_file)\n","print(\" SIze of my cnn model: {:.2f}MB\".format(cnn_model_size/1000))"],"execution_count":15,"outputs":[{"output_type":"stream","text":[" SIze of my cnn model: 153.78MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6fswY0LP6vdj","executionInfo":{"status":"error","timestamp":1602824211884,"user_tz":420,"elapsed":404,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"0ecf070e-9560-43d1-83af-a37460a830bd","colab":{"base_uri":"https://localhost:8080/","height":369}},"source":["\n","model=keras.models.load_model('/content/drive/My Drive/Colab/MS Project/My Model/CNN_Model.h5')\n","model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","base_loss,base_accuracy=model.evaluate(testX,testy,batch_size=batch_size,verbose=0)\n","print(base_loss,base_accuracy)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-693d77ab09fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab/MS Project/My Model/CNN_Model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbase_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_accuracy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtesty\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2567\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2569\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2570\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n","\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."]}]},{"cell_type":"code","metadata":{"id":"w0Vldri_p2iG","executionInfo":{"status":"ok","timestamp":1602361189488,"user_tz":420,"elapsed":566989,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"8e567d2e-aecd-4055-be3b-8f8a55957c07","colab":{"base_uri":"https://localhost:8080/","height":179}},"source":["!pip install tensorflow_model_optimization"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow_model_optimization\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/38/4fd48ea1bfcb0b6e36d949025200426fe9c3a8bfae029f0973d85518fa5a/tensorflow_model_optimization-0.5.0-py2.py3-none-any.whl (172kB)\n","\r\u001b[K     |██                              | 10kB 23.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 112kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 122kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 133kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 143kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 8.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow_model_optimization) (1.18.5)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_model_optimization) (0.1.5)\n","Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow_model_optimization) (1.15.0)\n","Installing collected packages: tensorflow-model-optimization\n","Successfully installed tensorflow-model-optimization-0.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LL7ACLxHvVa_"},"source":["import tensorflow_model_optimization as tfmot\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kfjk8gd7Un-o"},"source":["# %tensorboard --logdir={logdir}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sh4x5Etfq5_P"},"source":["##Post-Training Quantization[FLOAT16] on CNN model (tflite model)\n"]},{"cell_type":"code","metadata":{"id":"5VrXvlcaQ2_F","executionInfo":{"status":"ok","timestamp":1602361190487,"user_tz":420,"elapsed":567972,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"ce372749-6757-40bf-8b53-3a6c31ad7d3a","colab":{"base_uri":"https://localhost:8080/","height":161}},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_types = [tf.float16]\n","quantized_cnn_model = converter.convert()\n","\n","quantized_cnn_tflite_file = 'quantized_cnn_model.tflite'\n","\n","with open(quantized_cnn_tflite_file, 'wb') as f:\n","  f.write(quantized_cnn_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","INFO:tensorflow:Assets written to: /tmp/tmppjkut0cu/assets\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xqIQvI6xRMmb"},"source":["##Size of post-quantized CNN model"]},{"cell_type":"code","metadata":{"id":"xzdX8tOkRH8S","executionInfo":{"status":"ok","timestamp":1602361190496,"user_tz":420,"elapsed":567974,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"8980720a-c118-40a7-9d07-30ebd301b2df","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["quantized_cnn_model_size=get_zipped_model_size(quantized_cnn_tflite_file)\n","print(\" Size of quantized cnn model: {:.2f}MB\".format(quantized_cnn_model_size/1000))"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" Size of quantized cnn model: 77.83MB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0pSN2jc8SRFM"},"source":["##ACCURACY OF QUANTIZED MODEL"]},{"cell_type":"code","metadata":{"id":"vKylQdpqUhvw"},"source":["def evaluate_model(interpreter):\n","# Get input and output tensors.\n","  input_details = interpreter.get_input_details()\n","  output_details = interpreter.get_output_details()\n","  print(input_details)\n","  print(output_details)\n","  print(\"== Input details ==\")\n","  print(\"shape:\", input_details[0]['shape'])\n","  print(\"type:\", input_details[0]['dtype'])\n","  print(\"type:\", input_details[0]['index'])\n","  print(\"\\n== Output details ==\")\n","  print(\"shape:\", output_details[0]['shape'])\n","  print(\"type:\", output_details[0]['dtype'])\n","  print(\"type:\", output_details[0]['index'])\n","\n","\n","\n","  input_shape = input_details[0]['index']\n","  output_shape = output_details[0]['index']\n","\n","  # Run predictions on every image in the \"test\" dataset.\n","  prediction= []\n","  print(testX.shape)\n","  for i,test_data in enumerate(testX):\n","    # Pre-processing: add batch dimension and convert to float32 to match with\n","    # the model's input data format.\n","\n","    test_data = np.expand_dims(test_data, axis=0).astype(np.float32)\n","  \n","    interpreter.set_tensor(input_shape, test_data)\n","\n","    # Run inference.\n","    interpreter.invoke()\n","\n","    # Post-processing: remove batch dimension and find the digit with highest\n","    # probability.\n","    output = interpreter.get_tensor(output_shape)\n","    digit = np.argmax(output,axis=1)\n","    prediction.append(digit)\n","\n","  # Compare prediction results with ground truth labels to calculate accuracy.\n","  \n","  print('\\n')\n","  prediction=np.array(prediction)\n","  print(prediction.shape)\n","  print(testy.shape)\n","  labels=np.argmax(testy,axis=-1)\n","  accuracy_count=0\n","  for i in range(len(prediction)):\n","    \n","    if(prediction[i]==labels[i]).any():\n","      accuracy_count+=1\n","  \n","  accuracy=(accuracy_count/len(prediction))*100\n","\n","  return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"92lKFioJUovC","executionInfo":{"status":"ok","timestamp":1602361190760,"user_tz":420,"elapsed":568225,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"4f79434f-fc57-4ec4-81bb-fe3808611ce4","colab":{"base_uri":"https://localhost:8080/","height":339}},"source":["\n","interpreter=tf.lite.Interpreter(model_content=quantized_cnn_model)\n","interpreter.allocate_tensors()\n","\n","cnn_tflite_accuracy = evaluate_model(interpreter)\n","\n","print('Base TFLite test_accuracy:', cnn_tflite_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[{'name': 'input_1', 'index': 0, 'shape': array([  1, 128,   9], dtype=int32), 'shape_signature': array([ -1, 128,   9], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n","[{'name': 'Identity', 'index': 39, 'shape': array([1, 6], dtype=int32), 'shape_signature': array([-1,  6], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n","== Input details ==\n","shape: [  1 128   9]\n","type: <class 'numpy.float32'>\n","type: 0\n","\n","== Output details ==\n","shape: [1 6]\n","type: <class 'numpy.float32'>\n","type: 39\n","(2947, 128, 9)\n","\n","\n","(2947, 1)\n","(2947, 6)\n","Base TFLite test_accuracy: 97.11571089243299\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YmAm-qN3k-ra"},"source":["#ADD QUANTIZATION AWARE TRAINING"]},{"cell_type":"markdown","metadata":{"id":"XzzBGFp926_N"},"source":["#2.PRUNING CNN MODEL"]},{"cell_type":"code","metadata":{"id":"N_cbkqwJqLty","executionInfo":{"status":"ok","timestamp":1602361203230,"user_tz":420,"elapsed":580687,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"7728e613-b28e-4d31-ad8c-116b0f1b67f6","colab":{"base_uri":"https://localhost:8080/","height":837}},"source":["prune_low_mag=tfmot.sparsity.keras.prune_low_magnitude\n","batch_size=32\n","epoch=5\n","validation_split=0.3\n","\n","num=trainX.shape[0]*(1-validation_split)\n","end_step=np.ceil(num / batch_size).astype(np.int32) * epoch\n","pruning_params={\n","    'pruning_schedule':tfmot.sparsity.keras.PolynomialDecay\n","    (initial_sparsity=0.2,\n","     final_sparsity=0.8,\n","     begin_step=0,\n","     end_step=end_step)\n","}\n","\n","pruned_model=prune_low_mag(model,**pruning_params)\n","\n","pruned_model.compile(optimizer='adam',loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n","\n","pruned_model.summary()\n","\n","logdir = tempfile.mkdtemp()\n","\n","callbacks = [\n","  tfmot.sparsity.keras.UpdatePruningStep(),\n","  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n","]\n","\n","pruned_model.fit(trainX, trainy,\n","                  batch_size=batch_size, epochs=epoch, validation_split=validation_split,\n","                  callbacks=callbacks)\n","#Model accuracy\n","model_for_pruning_loss, model_for_pruning_accuracy = pruned_model.evaluate(\n","   testX, testy, verbose=0)\n","print(model_for_pruning_loss,model_for_pruning_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:200: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:200: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"functional_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 128, 9)]          0         \n","_________________________________________________________________\n","prune_low_magnitude_conv1d ( (None, 62, 64)            5826      \n","_________________________________________________________________\n","prune_low_magnitude_max_pool (None, 31, 64)            1         \n","_________________________________________________________________\n","prune_low_magnitude_conv1d_1 (None, 29, 128)           49282     \n","_________________________________________________________________\n","prune_low_magnitude_max_pool (None, 28, 128)           1         \n","_________________________________________________________________\n","prune_low_magnitude_conv1d_2 (None, 26, 32)            24610     \n","_________________________________________________________________\n","prune_low_magnitude_global_a (None, 32)                1         \n","_________________________________________________________________\n","prune_low_magnitude_batch_no (None, 32)                129       \n","_________________________________________________________________\n","prune_low_magnitude_dense (P (None, 6)                 392       \n","=================================================================\n","Total params: 80,242\n","Trainable params: 40,230\n","Non-trainable params: 40,012\n","_________________________________________________________________\n","Epoch 1/5\n","  2/161 [..............................] - ETA: 12s - loss: 1.0436 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0117s vs `on_train_batch_end` time: 0.1345s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0117s vs `on_train_batch_end` time: 0.1345s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["161/161 [==============================] - 2s 12ms/step - loss: 1.0449 - accuracy: 0.9990 - val_loss: 1.0450 - val_accuracy: 0.9995\n","Epoch 2/5\n","161/161 [==============================] - 1s 9ms/step - loss: 1.0536 - accuracy: 0.9913 - val_loss: 1.0564 - val_accuracy: 0.9896\n","Epoch 3/5\n","161/161 [==============================] - 1s 9ms/step - loss: 1.0656 - accuracy: 0.9825 - val_loss: 1.0648 - val_accuracy: 0.9841\n","Epoch 4/5\n","161/161 [==============================] - 2s 9ms/step - loss: 1.0820 - accuracy: 0.9679 - val_loss: 1.0734 - val_accuracy: 0.9764\n","Epoch 5/5\n","161/161 [==============================] - 1s 9ms/step - loss: 1.0713 - accuracy: 0.9771 - val_loss: 1.0674 - val_accuracy: 0.9810\n","1.1031721830368042 0.9429928660392761\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3PrKkYSYVSA7","executionInfo":{"status":"ok","timestamp":1602361203231,"user_tz":420,"elapsed":580681,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"1f40ea7a-7813-4c02-c995-883c9c837bc5","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["#model size\n","pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n","pruned_cnn_file = ('prune_cnn.h5')\n","tf.keras.models.save_model(pruned_model, pruned_cnn_file, include_optimizer=False)\n","print('Saved pruned Keras model to:', pruned_cnn_file)\n","pruned_cnn_model_size=get_zipped_model_size(pruned_cnn_file)\n","print(\" SIze of pruned cnn model: {:.2f}MB\".format(pruned_cnn_model_size/1000))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saved pruned Keras model to: prune_cnn.h5\n"," SIze of pruned cnn model: 51.97MB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P_sqlQtVY4-C"},"source":["#CONVERTING PRUNED MODEL TO TFLITE "]},{"cell_type":"code","metadata":{"id":"kjiR99cpY4Pm","executionInfo":{"status":"ok","timestamp":1602361204379,"user_tz":420,"elapsed":581821,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"5332177a-8dca-4263-8674-554beeb1c62e","colab":{"base_uri":"https://localhost:8080/","height":392}},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n","converter.experimental_new_converter = True\n","\n","cnn_pruned_model_tflite = converter.convert()\n","\n","cnn_pruned_tflite_file = 'cnn_pruned_model.tflite'\n","\n","with open(cnn_pruned_tflite_file, 'wb') as f:\n","  f.write(cnn_pruned_model_tflite)\n","\n","print('Saved CNN TFLite model to:', cnn_pruned_tflite_file)\n","\n","\n","interpreter=tf.lite.Interpreter(model_content=cnn_pruned_model_tflite)\n","interpreter.allocate_tensors()\n","\n","cnn_tflite_accuracy = evaluate_model(interpreter)\n","\n","print('Base TFLite test_accuracy:', cnn_tflite_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/tmppg9gar_f/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/tmppg9gar_f/assets\n"],"name":"stderr"},{"output_type":"stream","text":["Saved CNN TFLite model to: cnn_pruned_model.tflite\n","[{'name': 'input_1', 'index': 0, 'shape': array([  1, 128,   9], dtype=int32), 'shape_signature': array([ -1, 128,   9], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n","[{'name': 'Identity', 'index': 39, 'shape': array([1, 6], dtype=int32), 'shape_signature': array([-1,  6], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n","== Input details ==\n","shape: [  1 128   9]\n","type: <class 'numpy.float32'>\n","type: 0\n","\n","== Output details ==\n","shape: [1 6]\n","type: <class 'numpy.float32'>\n","type: 39\n","(2947, 128, 9)\n","\n","\n","(2947, 1)\n","(2947, 6)\n","Base TFLite test_accuracy: 94.29928741092637\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w9fmZ-kwZZ7R","executionInfo":{"status":"ok","timestamp":1602361204381,"user_tz":420,"elapsed":581814,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"205bf43a-860c-4012-8050-242c3af720a8","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cnn_pruned_model_size=get_zipped_model_size(cnn_pruned_tflite_file)\n","print(\" Size of quantized cnn model: {:.2f}MB\".format(cnn_pruned_model_size/1000))"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" Size of quantized cnn model: 50.22MB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7Tk86APZctEL"},"source":["#POST-TRIANING QUANTIZATION ON PRUNED CNN MODEL"]},{"cell_type":"code","metadata":{"id":"Qt6WNIrWcpEF","executionInfo":{"status":"ok","timestamp":1602361204622,"user_tz":420,"elapsed":582045,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"ac5a610d-540c-4eed-bab9-3eda9fdced4d","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","converter.target_spec.supported_types = [tf.float16]\n","quantized_pruned_cnn_model = converter.convert()\n","\n","quantized_pruned_cnn_tflite_file = 'quantized_pruned_cnn_model.tflite'\n","\n","with open(quantized_pruned_cnn_tflite_file, 'wb') as f:\n","  f.write(quantized_pruned_cnn_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/tmpzdr1yv9n/assets\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/tmpzdr1yv9n/assets\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0MthAb9zdhIp","executionInfo":{"status":"ok","timestamp":1602361204623,"user_tz":420,"elapsed":582039,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"c891a8a5-cec3-421b-8375-a2fe5b16f3aa","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["quantized_pruned_cnn_model_size=get_zipped_model_size(quantized_pruned_cnn_tflite_file)\n","print(\" Size of quantized cnn model: {:.2f}MB\".format(quantized_pruned_cnn_model_size/1000))"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" Size of quantized cnn model: 31.15MB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MER7e23urqZY","executionInfo":{"status":"ok","timestamp":1602361205556,"user_tz":420,"elapsed":582963,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"0078be46-9a98-40bc-ce77-b96600a95236","colab":{"base_uri":"https://localhost:8080/","height":339}},"source":["\n","interpreter=tf.lite.Interpreter(model_content=quantized_pruned_cnn_model)\n","interpreter.allocate_tensors()\n","\n","quantized_pruned_cnn_model_accuracy = evaluate_model(interpreter)\n","\n","print('Quantized and Pruned CNN TFLite test_accuracy:', quantized_pruned_cnn_model_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[{'name': 'input_1', 'index': 0, 'shape': array([  1, 128,   9], dtype=int32), 'shape_signature': array([ -1, 128,   9], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n","[{'name': 'Identity', 'index': 39, 'shape': array([1, 6], dtype=int32), 'shape_signature': array([-1,  6], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n","== Input details ==\n","shape: [  1 128   9]\n","type: <class 'numpy.float32'>\n","type: 0\n","\n","== Output details ==\n","shape: [1 6]\n","type: <class 'numpy.float32'>\n","type: 39\n","(2947, 128, 9)\n","\n","\n","(2947, 1)\n","(2947, 6)\n","Quantized and Pruned CNN TFLite test_accuracy: 94.29928741092637\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DXd2B1T6yWfR","executionInfo":{"status":"ok","timestamp":1602361205559,"user_tz":420,"elapsed":582958,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"257a72c6-16ae-4e0b-a849-e9b5519da99a","colab":{"base_uri":"https://localhost:8080/","height":353}},"source":["import matplotlib.pyplot as plt\n","\n","\n","\n","size=[cnn_model_size/1000,quantized_cnn_model_size/1000,pruned_cnn_model_size/1000,quantized_pruned_cnn_model_size/1000]\n","label=['cnn','quant_cnn_tflite','prune_cnn','quant_pruned_cnn']\n","\n","print(\"Size of gzipped baseline Keras model: %.2f KB\" % (cnn_model_size/1000))\n","print(\"Size of gzipped quantized Keras tflite model: %.2f KB\" % (quantized_cnn_model_size/1000))\n","print(\"Size of gzipped pruned Keras model: %.2f KB\" % (pruned_cnn_model_size/1000))\n","print(\"Size of gzipped quantized and pruned TFlite model: %.2f KB\" % (quantized_pruned_cnn_model_size/1000))\n","\n","plt.bar(label,height=size)\n","title_obj=plt.title('Size of baseline and pruned keras file')\n","plt.setp(title_obj, color='w')\n","plt.tick_params(axis='x', colors='white')\n","plt.tick_params(axis='y', colors='white')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Size of gzipped baseline Keras model: 153.75 KB\n","Size of gzipped quantized Keras tflite model: 77.83 KB\n","Size of gzipped pruned Keras model: 51.97 KB\n","Size of gzipped quantized and pruned TFlite model: 31.15 KB\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"dark"}}]},{"cell_type":"code","metadata":{"id":"868VAQgmzEDZ","executionInfo":{"status":"ok","timestamp":1602361205561,"user_tz":420,"elapsed":582952,"user":{"displayName":"Anisha Aswani","photoUrl":"","userId":"13283811541341339812"}},"outputId":"bc9a7778-8b5b-4e78-f18c-25d80a1d448a","colab":{"base_uri":"https://localhost:8080/","height":353}},"source":["model_accuracy=[score,cnn_tflite_accuracy,model_for_pruning_accuracy*100,quantized_pruned_cnn_model_accuracy]\n","label=['keras_file','keras_tflite_file','pruned_keras_file','pruned_tflite_file']\n","\n","print(\"Accuracy baseline Keras model: %.2f bytes\" % (score))\n","print(\"Accuracy Keras tflite model: %.2f bytes\" % (cnn_tflite_accuracy))\n","print(\"Accuracy pruned Keras model: %.2f bytes\" % (model_for_pruning_accuracy*100))\n","print(\"Accuracy pruned TFlite model: %.2f bytes\" % (quantized_pruned_cnn_model_accuracy))\n","\n","plt.bar(label,height=model_accuracy)\n","title_obj=plt.title('Size of baseline and pruned keras file')\n","plt.setp(title_obj, color='w')\n","plt.tick_params(axis='x', colors='white')\n","plt.tick_params(axis='y', colors='white')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy baseline Keras model: 97.12 bytes\n","Accuracy Keras tflite model: 94.30 bytes\n","Accuracy pruned Keras model: 94.30 bytes\n","Accuracy pruned TFlite model: 94.30 bytes\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"dark"}}]}]}