{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Qkeras with pruning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1miUoB4oiUak"
      },
      "source": [
        "#Importing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQX_rg7Z57Ud"
      },
      "source": [
        "#Tensorflow version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhaeNekPmHu1"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_KQZKwjzI2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4581be8-6980-4e71-cab8-5771bc2480e5"
      },
      "source": [
        "!pip install tensorflow_model_optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.6)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.19.5)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SRrh5rHiDHo",
        "outputId": "24841619-beaa-47cd-d7aa-d35f31a46c53"
      },
      "source": [
        "!git clone https://github.com/google/qkeras.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'qkeras' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTIqBHwQiHev",
        "outputId": "64a42e0e-7b88-4953-952b-2bafa37ff43a"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/UCI HAR Dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-09 08:25:15--  https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60999314 (58M) [application/x-httpd-php]\n",
            "Saving to: ‘UCI HAR Dataset.zip.2’\n",
            "\n",
            "UCI HAR Dataset.zip 100%[===================>]  58.17M  83.4MB/s    in 0.7s    \n",
            "\n",
            "2021-06-09 08:25:16 (83.4 MB/s) - ‘UCI HAR Dataset.zip.2’ saved [60999314/60999314]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzNd__e7zBU8"
      },
      "source": [
        "import sys\n",
        "sys.path.append('qkeras')\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from qkeras import *\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_Hq0VUMvJx9"
      },
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from scipy import ndimage\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D,Conv2D\n",
        "from keras.layers.convolutional import MaxPooling1D,MaxPooling2D\n",
        "from keras.layers import BatchNormalization,ReLU,GlobalAveragePooling1D,MaxPooling1D,LSTM,TimeDistributed,GlobalAveragePooling2D\n",
        "#from keras.utils import to_categorical\n",
        "from keras.models import save_model, load_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from tensorflow.keras.utils import  plot_model\n",
        "from keras.models import Model,save_model,load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.merge import concatenate\n",
        "import numpy as np\n",
        "from six.moves import zip\n",
        "from tensorflow.keras import callbacks\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from qkeras import QActivation\n",
        "from qkeras import QDense\n",
        "from qkeras import QConv2D\n",
        "from qkeras import quantized_bits\n",
        "from qkeras.utils import load_qmodel\n",
        "from qkeras.utils import print_model_sparsity\n",
        "from tensorflow_model_optimization import sparsity\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import prune\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\n",
        "\n",
        "from qkeras.estimate import print_qstats\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import expand_dims\n",
        "from tensorflow import keras\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8tRrh2Q2gnB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e224f177-5cd8-4a61-a73c-e5aaae25c071"
      },
      "source": [
        "!pip install -U tensorboard_plugin_profile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboard_plugin_profile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/4e/0bf160776e5dacdba5105a580aa57a2bd37c1cc4faa1bd7695d82e7d6ae7/tensorboard_plugin_profile-2.4.0-py3-none-any.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 24.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 23.1MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 17.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 14.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 8.8MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |██▎                             | 81kB 9.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 10.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 102kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 122kB 8.2MB/s eta 0:00:01\r\u001b[K     |███▊                            | 133kB 8.2MB/s eta 0:00:01\r\u001b[K     |████                            | 143kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 153kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 163kB 8.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 174kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 194kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 204kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 215kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 225kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 235kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 245kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 256kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 266kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 276kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 286kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 296kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 307kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 317kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 327kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 337kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 348kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 358kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 368kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 378kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 389kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 399kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 409kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 419kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 430kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 440kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 450kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 460kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 471kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 481kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 491kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 501kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 512kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 522kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 532kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 542kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 552kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 563kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 573kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 583kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 593kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 604kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 614kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 624kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 634kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 645kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 655kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 665kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 675kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 686kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 696kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 706kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 716kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 727kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 737kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 747kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 757kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 768kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 778kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 788kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 798kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 808kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 819kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 829kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 839kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 849kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 860kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 870kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 880kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 890kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 901kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 911kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 921kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 931kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 942kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 952kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 962kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 972kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 983kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 993kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1MB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 8.2MB/s \n",
            "\u001b[?25hCollecting gviz-api>=1.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/8f/c6f16235a16b3dc4efdcf34dbc93b3b6f678b88176dbd6a36c75d678888f/gviz_api-1.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (1.15.0)\n",
            "Installing collected packages: gviz-api, tensorboard-plugin-profile\n",
            "Successfully installed gviz-api-1.9.0 tensorboard-plugin-profile-2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INpMNpCdimZr"
      },
      "source": [
        "#Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vYcHaInEDoK"
      },
      "source": [
        "def load_file(filepath):\n",
        "  dataframe=read_csv(filepath,header=None,delim_whitespace=True)\n",
        "  return dataframe.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7akEplVIDyX"
      },
      "source": [
        "def load_group(filenames,prefix=''):\n",
        "  loaded=list()\n",
        "  for name in filenames:\n",
        "    data=load_file(prefix+name)\n",
        "    loaded.append(data)\n",
        "  loaded=dstack(loaded)\n",
        "  return loaded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKHYErTsIYac"
      },
      "source": [
        "def load_dataset_group(group,prefix=''):\n",
        "  filepath=prefix+group+'/Inertial Signals/'\n",
        "  filenames=list()\n",
        "  filenames+=['total_acc_x_'+group+'.txt','total_acc_y_'+group+'.txt','total_acc_z_'+group+'.txt']\n",
        "  filenames+=['body_acc_x_'+group+'.txt','body_acc_y_'+group+'.txt','body_acc_z_'+group+'.txt']\n",
        "  filenames+=['body_gyro_x_'+group+'.txt','body_gyro_y_'+group+'.txt','body_gyro_z_'+group+'.txt']\n",
        "  X=load_group(filenames,filepath)\n",
        "  y=load_file(prefix+group+'/y_'+group+'.txt')\n",
        "  return (X,y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuWfdQHuJt9f"
      },
      "source": [
        "def load_dataset(prefix=''):\n",
        "  trainX,trainy=load_dataset_group('train',prefix+'UCI HAR Dataset/')\n",
        "  print(trainX.shape,trainy.shape)\n",
        "  testX,testy=load_dataset_group('test',prefix+'UCI HAR Dataset/')\n",
        "  print(testX.shape,testy.shape)\n",
        "  trainy=trainy-1\n",
        "  testy=testy-1\n",
        "  trainy=to_categorical(trainy)\n",
        "  testy=to_categorical(testy)\n",
        "  print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "  return trainX, trainy, testX, testy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Mtbf_PSH87"
      },
      "source": [
        "def scale_data(trainX, testX):\n",
        "\t# remove overlap\n",
        "\tcut = int(trainX.shape[1] / 2)\n",
        "\tlongX = trainX[:, -cut:, :]\n",
        "\t# flatten windows\n",
        "\tlongX = longX.reshape((longX.shape[0] * longX.shape[1], longX.shape[2]))\n",
        "\t# flatten train and test\n",
        "\tflatTrainX = trainX.reshape((trainX.shape[0] * trainX.shape[1], trainX.shape[2]))\n",
        "\tflatTestX = testX.reshape((testX.shape[0] * testX.shape[1], testX.shape[2]))\n",
        "\t# standardize\n",
        "\n",
        "\ts = StandardScaler()\n",
        "\t\t# fit on training data\n",
        "\ts.fit(longX)\n",
        "\t\t# apply to training and test data\n",
        "\tlongX = s.transform(longX)\n",
        "\tflatTrainX = s.transform(flatTrainX)\n",
        "\tflatTestX = s.transform(flatTestX)\n",
        "\t# reshape\n",
        "\tflatTrainX = flatTrainX.reshape((trainX.shape))\n",
        "\tflatTestX = flatTestX.reshape((testX.shape))\n",
        "\treturn flatTrainX, flatTestX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dow8qJO4myQ"
      },
      "source": [
        "##Function for model size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytB8g1p74mEU"
      },
      "source": [
        "def get_zipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  zipped_file = file+'.zip'\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JyEh2LQyggX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af6af0d-ecd9-4fc0-de89-99b135a0e2bc"
      },
      "source": [
        "optimizer=Adam(lr=0.0001)\n",
        "with_bn=1\n",
        "THRESHOLD=0.1\n",
        "\n",
        "class LearningRateAdjuster(callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    self.learning_rate_factor = 1.0\n",
        "    pass\n",
        "\n",
        "  def on_epoch_end(self, epochs, logs):\n",
        "    max_variance = -1\n",
        "\n",
        "    for layer in self.model.layers:\n",
        "      if layer.__class__.__name__ in [\n",
        "          \"BatchNormalization\",\n",
        "          \"QBatchNormalization\"\n",
        "      ]:\n",
        "        variance = np.max(layer.get_weights()[-1])\n",
        "        if variance > max_variance:\n",
        "          max_variance = variance\n",
        "\n",
        "    if max_variance > 32 and self.learning_rate_factor < 100:\n",
        "      learning_rate = K.get_value(self.model.optimizer.learning_rate)\n",
        "      self.learning_rate_factor /= 2.0\n",
        "      print(\"***** max_variance is {} / lr is {} *****\".format(\n",
        "          max_variance, learning_rate))\n",
        "      K.eval(K.update(\n",
        "          self.model.optimizer.learning_rate, learning_rate / 2.0\n",
        "      ))\n",
        "\n",
        "lra = LearningRateAdjuster()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOWuN0ZroUDR"
      },
      "source": [
        "##1. CNN MODEL\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7BkQ1pYraEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ffb29c-6e94-4899-b73a-484068574b67"
      },
      "source": [
        "trainX,trainy,testX,testy=load_dataset()\n",
        "verbose,epochs,batch_size=1,50,32 #50\n",
        "n_timesteps,n_features,n_outputs=trainX.shape[1],trainX.shape[2],trainy.shape[1]\n",
        "print('n step: ', n_timesteps)\n",
        "print('features: ',n_features)\n",
        "trainX,testX=scale_data(trainX,testX)\n",
        "print(trainX.shape)\n",
        "prune_whole_model=True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
            "n step:  128\n",
            "features:  9\n",
            "(7352, 128, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yciMN9WVMkpd"
      },
      "source": [
        "\n",
        "'''\n",
        "\n",
        "inputs=keras.Input(shape=(n_timesteps,n_features))\n",
        "\n",
        "\n",
        "conv_1=tf.keras.layers.Conv1D(filters=64,kernel_size=5,strides=2,activation='relu')(inputs)\n",
        "maxpool_1=tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)(conv_1)\n",
        "\n",
        "conv_2=tf.keras.layers.Conv1D(filters=128,kernel_size=3,strides=1,activation='relu')(maxpool_1)\n",
        "maxpool_2=tf.keras.layers.MaxPooling1D(pool_size=2,strides=1)(conv_2)\n",
        "\n",
        "conv_3=tf.keras.layers.Conv1D(filters=32,kernel_size=3,strides=1,activation='relu')(maxpool_2)\n",
        "avg_pooling=tf.keras.layers.GlobalAveragePooling1D()(conv_3)\n",
        "batch_norm=tf.keras.layers.BatchNormalization()(avg_pooling)\n",
        "\n",
        "output=tf.keras.layers.Dense(n_outputs,activation='softmax')(batch_norm)\n",
        "model=tf.keras.Model(inputs=inputs,outputs=output)\n",
        "'''\n",
        "def build_model(n_timesteps,n_features):\n",
        "  x=x_in=Input(shape=(n_timesteps,n_features),name='input')\n",
        "  x=QActivation(\"quantized_relu_po2(4,1)\",name=\"acti\")(x)\n",
        "  x=QConv1D(filters=64, kernel_size=3,\n",
        "      strides=1,\n",
        "      kernel_quantizer=quantized_po2(4, 1),\n",
        "      bias_quantizer=quantized_bits(4,2,0) if not with_bn else None,\n",
        "      bias_range=4 if not with_bn else None,\n",
        "      use_bias=not with_bn,\n",
        "      name=\"conv1d_0_m\")(x)\n",
        "  x = QActivation(\"quantized_relu(3,1)\", name=\"act0_m\")(x)\n",
        "  x=tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)(x)\n",
        "  x=QConv1D(filters=128, kernel_size=3,\n",
        "      strides=1,\n",
        "      kernel_quantizer=quantized_po2(4, 1),\n",
        "      bias_quantizer=quantized_bits(4,2,1) if not with_bn else None,\n",
        "      bias_range=4 if not with_bn else None,\n",
        "      use_bias=not with_bn,\n",
        "      name=\"conv1d_1_m\")(x)\n",
        "  x = QActivation(\"quantized_relu(3,1)\", name=\"act1_m\")(x)\n",
        "  x=tf.keras.layers.MaxPooling1D(pool_size=2,strides=2)(x)\n",
        "  x=QConv1D(filters=32, kernel_size=3,\n",
        "      strides=1,\n",
        "      kernel_quantizer=quantized_po2(4, 1),\n",
        "      bias_quantizer=quantized_bits(4,2,2) if not with_bn else None,\n",
        "      bias_range=4 if not with_bn else None,\n",
        "      use_bias=not with_bn,\n",
        "      name=\"conv1d_2_m\")(x)\n",
        "  x = QActivation(\"quantized_relu(3,1)\", name=\"act2_m\")(x)\n",
        "  x=tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "  if with_bn:\n",
        "    x=QBatchNormalization(\n",
        "        gamma_quantizer=quantized_relu_po2(4,8),\n",
        "        variance_quantizer=quantized_relu_po2(6),\n",
        "        beta_quantizer=quantized_po2(4, 4),\n",
        "        gamma_range=8,\n",
        "        beta_range=4,\n",
        "        name=\"bn1\")(x)\n",
        "  x = QActivation(\"quantized_relu(3,1)\", name=\"act3_m\")(x)\n",
        "  x = Flatten()(x)\n",
        "  x = QDense(\n",
        "      n_outputs,\n",
        "      kernel_quantizer=quantized_ulaw(4, 0, 1),\n",
        "      bias_quantizer=quantized_bits(4, 0, 1),\n",
        "      name=\"dense\")(\n",
        "          x)\n",
        "  x = Activation(\"softmax\", name=\"softmax\")(x)\n",
        "  model = Model(inputs=[x_in], outputs=[x])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEENq8DHseVI"
      },
      "source": [
        "def train_and_save(model,trainX,trainy,testX,testy):\n",
        "\n",
        "  plot_model(model, show_shapes=True, to_file='CNN_Model.png')\n",
        "  model.compile(\n",
        "      loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "  model.summary()\n",
        "  callbacks = [\n",
        "        pruning_callbacks.UpdatePruningStep(),\n",
        "        #pruning_callbacks.PruningSummaries(log_dir=tempfile.mkdtemp())\n",
        "        pruning_callbacks.PruningSummaries(log_dir=\"mnist_prune\")\n",
        "    ]\n",
        "  model.fit(\n",
        "      trainX, trainy, batch_size=batch_size,\n",
        "      epochs=epochs, initial_epoch=1, verbose=1,\n",
        "      validation_data=(testX,testy),\n",
        "      callbacks=callbacks)\n",
        "  score = model.evaluate(testX, testy, verbose=False)\n",
        "  print(\"Test score:\", score[0])\n",
        "  print(\"Test accuracy:\", score[1])\n",
        "  print_model_sparsity(model)\n",
        "  keras_file='pruned_model.h5'\n",
        "  print(\"Saving mode to: \",keras_file)\n",
        "  save_model(model,keras_file)\n",
        "  print(\"Reloading model\")\n",
        "  with prune.prune_scope():\n",
        "      loaded_model = load_qmodel(keras_file)\n",
        "  score = loaded_model.evaluate(testX, testy, verbose=0)\n",
        "  print(\"Test loss:\", score[0])\n",
        "  print(\"Test accuracy:\", score[1])\n",
        "\n",
        "  return keras_file,model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umyv_Q97dd98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e84515-8f99-4752-e3bd-6e589402e413"
      },
      "source": [
        "batch_size=batch_size\n",
        "epoch=500\n",
        "validation_split=0.3\n",
        "num=trainX.shape[0]*(1-validation_split)\n",
        "pruning_params = {\n",
        "        \"pruning_schedule\":\n",
        "            tfmot.sparsity.keras.PolynomialDecay(\n",
        "    initial_sparsity=0.1, final_sparsity=0.9,begin_step=0,end_step=np.ceil(num / batch_size).astype(np.int32) * 5)\n",
        "    }\n",
        "    \n",
        "if prune_whole_model:\n",
        "      model = build_model(n_timesteps,n_features)\n",
        "      model = prune.prune_low_magnitude(model, **pruning_params)\n",
        "else:\n",
        "      model = build_layerwise_model(input_shape, **pruning_params)\n",
        "\n",
        "keras_file,model=train_and_save(model, trainX, trainy, testX, testy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "qkeras/qkeras/qnormalization.py:81: UserWarning: gamma_range is deprecated in QBatchNormalization layer.\n",
            "  warnings.warn('gamma_range is deprecated in QBatchNormalization layer.')\n",
            "qkeras/qkeras/qnormalization.py:84: UserWarning: beta_range is deprecated in QBatchNormalization layer.\n",
            "  warnings.warn('beta_range is deprecated in QBatchNormalization layer.')\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2191: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 128, 9)]          0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_acti (Pr (None, 128, 9)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_0 (None, 126, 64)           3458      \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_act0_m ( (None, 126, 64)           1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 63, 64)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (None, 61, 128)           49154     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_act1_m ( (None, 61, 128)           1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 30, 128)           1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (None, 28, 32)            24578     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_act2_m ( (None, 28, 32)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_global_a (None, 32)                1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_bn1 (Pru (None, 32)                129       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_act3_m ( (None, 32)                1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 32)                1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 6)                 392       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_softmax  (None, 6)                 1         \n",
            "=================================================================\n",
            "Total params: 77,721\n",
            "Trainable params: 38,854\n",
            "Non-trainable params: 38,867\n",
            "_________________________________________________________________\n",
            "Epoch 2/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "  3/230 [..............................] - ETA: 1:42 - loss: 2.6352 - accuracy: 0.3542WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0110s vs `on_train_batch_begin` time: 0.0847s). Check your callbacks.\n",
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0110s vs `on_train_batch_end` time: 0.0643s). Check your callbacks.\n",
            "230/230 [==============================] - 41s 24ms/step - loss: 0.5459 - accuracy: 0.8175 - val_loss: 0.7865 - val_accuracy: 0.7061\n",
            "Epoch 3/5\n",
            "230/230 [==============================] - 4s 16ms/step - loss: 0.4395 - accuracy: 0.8636 - val_loss: 0.5951 - val_accuracy: 0.8677\n",
            "Epoch 4/5\n",
            "230/230 [==============================] - 4s 16ms/step - loss: 0.7561 - accuracy: 0.7715 - val_loss: 0.9647 - val_accuracy: 0.6420\n",
            "Epoch 5/5\n",
            "230/230 [==============================] - 4s 16ms/step - loss: 0.8343 - accuracy: 0.7693 - val_loss: 0.7749 - val_accuracy: 0.8280\n",
            "Test score: 0.7749223709106445\n",
            "Test accuracy: 0.8279606103897095\n",
            "Model Sparsity Summary (model)\n",
            "--\n",
            "prune_low_magnitude_conv1d_0_m: (conv1d_0_m/kernel:0, 0.8998842592592593)\n",
            "prune_low_magnitude_conv1d_1_m: (conv1d_1_m/kernel:0, 0.8999837239583334)\n",
            "prune_low_magnitude_conv1d_2_m: (conv1d_2_m/kernel:0, 0.8999837239583334)\n",
            "prune_low_magnitude_dense: (dense/kernel:0, 0.9010416666666666)\n",
            "\n",
            "\n",
            "Saving mode to:  pruned_model.h5\n",
            "Reloading model\n",
            "Test loss: 0.7749223709106445\n",
            "Test accuracy: 0.8279606103897095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2vsYhbK2tvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8764ea9-0ed3-4b59-912f-0a8a58dc3b7d"
      },
      "source": [
        "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
        "                                                 histogram_freq = 1,\n",
        "                                                 )\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 128, 9)]          0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_acti (Pr (None, 128, 9)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_0 (None, 126, 64)           3458      \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_act0_m ( (None, 126, 64)           1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 63, 64)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_1 (None, 61, 128)           49154     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_act1_m ( (None, 61, 128)           1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 30, 128)           1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv1d_2 (None, 28, 32)            24578     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_act2_m ( (None, 28, 32)            1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_global_a (None, 32)                1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_bn1 (Pru (None, 32)                129       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_act3_m ( (None, 32)                1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten  (None, 32)                1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 6)                 392       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_softmax  (None, 6)                 1         \n",
            "=================================================================\n",
            "Total params: 77,721\n",
            "Trainable params: 38,854\n",
            "Non-trainable params: 38,867\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWbQqribe1RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e00fce-12c9-4837-f127-6ee04f83e1a2"
      },
      "source": [
        "model_size=get_zipped_model_size(keras_file)\n",
        "print(\" Size of pruned qkeras cnn model: {:.2f}KB\".format(model_size/1000))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Size of pruned qkeras cnn model: 336.86KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpLSrPJyaYxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d279e63d-3593-4c6d-e18b-bf8ee7b8bbd9"
      },
      "source": [
        "model=tfmot.sparsity.keras.strip_pruning(model)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 128, 9)]          0         \n",
            "_________________________________________________________________\n",
            "acti (QActivation)           (None, 128, 9)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_0_m (QConv1D)         (None, 126, 64)           1728      \n",
            "_________________________________________________________________\n",
            "act0_m (QActivation)         (None, 126, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 63, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1_m (QConv1D)         (None, 61, 128)           24576     \n",
            "_________________________________________________________________\n",
            "act1_m (QActivation)         (None, 61, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 30, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2_m (QConv1D)         (None, 28, 32)            12288     \n",
            "_________________________________________________________________\n",
            "act2_m (QActivation)         (None, 28, 32)            0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "bn1 (QBatchNormalization)    (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "act3_m (QActivation)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (QDense)               (None, 6)                 198       \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 6)                 0         \n",
            "=================================================================\n",
            "Total params: 38,918\n",
            "Trainable params: 38,854\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPPugtvQsCu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "403cc6d1-3a5c-461a-c5ef-eef733cf0a59"
      },
      "source": [
        "for i, w in enumerate(model.get_weights()):\n",
        "    print(\n",
        "        \"{} -- Total:{}, Zeros: {:.2f}%\".format(\n",
        "            model.weights[i].name, w.size, np.sum(w == 0) / w.size * 100\n",
        "        )\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv1d_0_m/kernel:0 -- Total:1728, Zeros: 89.99%\n",
            "conv1d_1_m/kernel:0 -- Total:24576, Zeros: 90.00%\n",
            "conv1d_2_m/kernel:0 -- Total:12288, Zeros: 90.00%\n",
            "bn1/gamma:0 -- Total:32, Zeros: 0.00%\n",
            "bn1/beta:0 -- Total:32, Zeros: 3.12%\n",
            "bn1/moving_mean:0 -- Total:32, Zeros: 0.00%\n",
            "bn1/moving_variance:0 -- Total:32, Zeros: 0.00%\n",
            "dense/kernel:0 -- Total:192, Zeros: 90.10%\n",
            "dense/bias:0 -- Total:6, Zeros: 0.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpqdYxJ_sHDz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}